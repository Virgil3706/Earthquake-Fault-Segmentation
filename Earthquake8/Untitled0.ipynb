{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1ujpvKTnJDjhr70hY2HnKWZnxKCY4mUKf","authorship_tag":"ABX9TyM9X2Gk6Q3iV19bnsHkyNvD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"v4ElX7sSPv2U","colab_type":"code","outputId":"ab16da3f-3156-477b-a0e2-4b1b02c79692","executionInfo":{"status":"ok","timestamp":1584358528797,"user_tz":-480,"elapsed":1235,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["cd /content/drive/My Drive/Earthquake/Earthquake6"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Earthquake/Earthquake6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uGBuOAvwILuN","colab_type":"code","outputId":"df0538e2-f613-4fe7-afe8-a07e1730173e","executionInfo":{"status":"ok","timestamp":1584460963998,"user_tz":-480,"elapsed":1360,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c_9Q8-13Wcdt","colab_type":"code","colab":{}},"source":["run train.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UUvZ6ISSWd0o","colab_type":"code","colab":{}},"source":["run test.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_08Rpqh2Z3Vc","colab_type":"code","outputId":"42651547-f209-4bcf-b322-4bb478ffe424","executionInfo":{"status":"ok","timestamp":1584345578863,"user_tz":-480,"elapsed":6920,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":335}},"source":["pip install cmapy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting cmapy\n","  Downloading https://files.pythonhosted.org/packages/25/47/f1d2c686253bea1454cc7db687a09ae912fbe4648a86ef7fcd9765f7639f/cmapy-0.6.6.tar.gz\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cmapy) (3.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cmapy) (1.17.5)\n","Requirement already satisfied: opencv-python>=3.3 in /usr/local/lib/python3.6/dist-packages (from cmapy) (4.1.2.30)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (2.4.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (2.6.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (0.10.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->cmapy) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->cmapy) (45.2.0)\n","Building wheels for collected packages: cmapy\n","  Building wheel for cmapy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cmapy: filename=cmapy-0.6.6-cp36-none-any.whl size=3959 sha256=81e7c2d7750f75ebf6e7ea8fb7a917d7663a40a843feae0f5c5e46937738a120\n","  Stored in directory: /root/.cache/pip/wheels/6d/75/b1/b8645ff93df032bd16a383e7774e03d904476450d767fb1dcf\n","Successfully built cmapy\n","Installing collected packages: cmapy\n","Successfully installed cmapy-0.6.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DNFBEkjLbOfb","colab_type":"code","colab":{}},"source":["%run save_predicted_picture.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hTwvi8eu-E_A","colab":{}},"source":["import zipfile\n","path = '/content/drive/My Drive/original_data/seistrain.zip'\n","zip_file = zipfile.ZipFile(path)\n","zip_list = zip_file.namelist() # 得到压缩包里所有文件\n","\n","for f in zip_list:\n","    zip_file.extract(f, '/content/drive/My Drive/data') # 循环解压文件到指定目录\n"," \n","zip_file.close() # 关闭文件，必须有，释放内存\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dk4QDAfm-fn-","colab_type":"code","outputId":"3078c448-d5dc-4cb2-984d-8e804c3f4073","executionInfo":{"status":"ok","timestamp":1584358306522,"user_tz":-480,"elapsed":12719790,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python train.py --config config2.json"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1680007168 bytes == 0x4e80000 @  0x7f4524c291e7 0x7f4522446f71 0x7f45224af936 0x7f45224b060e 0x7f452254798f 0x50ac25 0x50d390 0x508245 0x50a080 0x50aa7d 0x50d390 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x509642 0x595311 0x54a6ff 0x551b81 0x5a067e 0x50d966 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d\n","load in 24.70939040184021 sec\n","seismic.shape, fault.shape (350, 500, 1200) (350, 500, 1200)\n","seismic.max(), seismic.min(), fault.max(), fault.min() 1.0 0.0 True False\n","pixelThre  276\n","horizontal_splits_number 24\n","width_after_pad 1200\n","left_pad,right_pad 0 0\n","vertical_splits_number 10\n","height_after_pad 528\n","top_pad,bottom_pad 14 14\n","len(Y) 19379\n","len(X) 19379\n","X[0].shape (96, 96)\n","read images in 1.2633168697357178 sec\n","(19379, 96, 96)\n","(19379, 96, 96)\n","read images in 1.1667680740356445 sec\n","(19379, 96, 96, 1)\n","(19379, 96, 96, 1)\n","3474\n","3474\n","(96, 96)\n","read images in 0.17623519897460938 sec\n","(3474, 96, 96)\n","(3474, 96, 96)\n","read images in 0.09291601181030273 sec\n","(3474, 96, 96, 1)\n","(3474, 96, 96, 1)\n","X_train (19379, 96, 96, 1)\n","X_val (3474, 96, 96, 1)\n","Y_train (19379, 96, 96, 1)\n","Y_val (3474, 96, 96, 1)\n","X_train (19379, 1, 96, 96)\n","X_val (3474, 1, 96, 96)\n","Y_train (19379, 1, 96, 96)\n","Y_val (3474, 1, 96, 96)\n","HED(\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (conv1_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv1_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv3_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv3_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv4_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv4_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv4_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv5_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","  (conv5_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","  (conv5_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n","  (relu): ReLU()\n","  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=True)\n","  (conv1_2_down): Conv2d(32, 21, kernel_size=(1, 1), stride=(1, 1))\n","  (conv2_2_down): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n","  (conv3_3_down): Conv2d(128, 21, kernel_size=(1, 1), stride=(1, 1))\n","  (conv4_3_down): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n","  (conv5_3_down): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n","  (score_dsn1): Conv2d(21, 1, kernel_size=(1, 1), stride=(1, 1))\n","  (score_dsn2): Conv2d(21, 1, kernel_size=(1, 1), stride=(1, 1))\n","  (score_dsn3): Conv2d(21, 1, kernel_size=(1, 1), stride=(1, 1))\n","  (score_dsn4): Conv2d(21, 1, kernel_size=(1, 1), stride=(1, 1))\n","  (score_dsn5): Conv2d(21, 1, kernel_size=(1, 1), stride=(1, 1))\n","  (score_final): Conv2d(5, 1, kernel_size=(1, 1), stride=(1, 1))\n",")\n","HED\n","<function cross_entropy_loss_HED at 0x7f44a44580d0>\n","modelNo 2\n","Train Epoch: 1 [0/152 (0%)] Loss: 609895.187500\n","Train Epoch: 1 [11/152 (7%)] Loss: 620029.500000\n","Train Epoch: 1 [22/152 (14%)] Loss: 588789.312500\n","Train Epoch: 1 [33/152 (22%)] Loss: 637970.687500\n","Train Epoch: 1 [44/152 (29%)] Loss: 624169.937500\n","Train Epoch: 1 [55/152 (36%)] Loss: 601726.812500\n","Train Epoch: 1 [66/152 (43%)] Loss: 616347.937500\n","Train Epoch: 1 [77/152 (51%)] Loss: 609223.562500\n","Train Epoch: 1 [88/152 (58%)] Loss: 598990.000000\n","Train Epoch: 1 [99/152 (65%)] Loss: 651543.312500\n","Train Epoch: 1 [110/152 (72%)] Loss: 662052.187500\n","Train Epoch: 1 [121/152 (80%)] Loss: 630686.937500\n","Train Epoch: 1 [132/152 (87%)] Loss: 581808.062500\n","Train Epoch: 1 [143/152 (94%)] Loss: 579092.812500\n","    learning Rate  : 1e-06\n","    loss           : 608996.3152754934\n","    IoU            : 0.08130290359258652\n","    accuracy1      : 0.4999482289290103\n","    val_loss       : 643220.0920758928\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","modelNo 2\n","Train Epoch: 2 [0/152 (0%)] Loss: 585320.062500\n","Train Epoch: 2 [11/152 (7%)] Loss: 603744.437500\n","Train Epoch: 2 [22/152 (14%)] Loss: 641978.312500\n","Train Epoch: 2 [33/152 (22%)] Loss: 591550.562500\n","Train Epoch: 2 [44/152 (29%)] Loss: 639990.375000\n","Train Epoch: 2 [55/152 (36%)] Loss: 578642.187500\n","Train Epoch: 2 [66/152 (43%)] Loss: 630752.437500\n","Train Epoch: 2 [77/152 (51%)] Loss: 644628.812500\n","Train Epoch: 2 [88/152 (58%)] Loss: 571951.562500\n","Train Epoch: 2 [99/152 (65%)] Loss: 612315.125000\n","Train Epoch: 2 [110/152 (72%)] Loss: 585431.687500\n","Train Epoch: 2 [121/152 (80%)] Loss: 603876.437500\n","Train Epoch: 2 [132/152 (87%)] Loss: 578197.062500\n","Train Epoch: 2 [143/152 (94%)] Loss: 604557.625000\n","    learning Rate  : 1e-06\n","    loss           : 608425.7182360197\n","    IoU            : 0.08132164925336838\n","    accuracy1      : 0.5\n","    val_loss       : 643196.9291294643\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","modelNo 2\n","Train Epoch: 3 [0/152 (0%)] Loss: 609797.187500\n","Train Epoch: 3 [11/152 (7%)] Loss: 605305.062500\n","Train Epoch: 3 [22/152 (14%)] Loss: 621766.875000\n","Train Epoch: 3 [33/152 (22%)] Loss: 573778.000000\n","Train Epoch: 3 [44/152 (29%)] Loss: 600679.437500\n","Train Epoch: 3 [55/152 (36%)] Loss: 592889.500000\n","Train Epoch: 3 [66/152 (43%)] Loss: 620997.062500\n","Train Epoch: 3 [77/152 (51%)] Loss: 627640.437500\n","Train Epoch: 3 [88/152 (58%)] Loss: 608718.062500\n","Train Epoch: 3 [99/152 (65%)] Loss: 548142.437500\n","Train Epoch: 3 [110/152 (72%)] Loss: 581695.062500\n","Train Epoch: 3 [132/152 (87%)] Loss: 614123.625000\n","Train Epoch: 3 [143/152 (94%)] Loss: 606016.937500\n","    learning Rate  : 1e-06\n","    loss           : 608362.8674958881\n","    IoU            : 0.08131790906190872\n","    accuracy1      : 0.5\n","    val_loss       : 643212.3618861607\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 1\n","modelNo 2\n","Train Epoch: 4 [0/152 (0%)] Loss: 608438.750000\n","Train Epoch: 4 [11/152 (7%)] Loss: 612737.312500\n","Train Epoch: 4 [22/152 (14%)] Loss: 616056.250000\n","Train Epoch: 4 [33/152 (22%)] Loss: 606331.187500\n","Train Epoch: 4 [44/152 (29%)] Loss: 606335.062500\n","Train Epoch: 4 [55/152 (36%)] Loss: 627618.750000\n","Train Epoch: 4 [66/152 (43%)] Loss: 603985.312500\n","Train Epoch: 4 [77/152 (51%)] Loss: 583799.750000\n","Train Epoch: 4 [88/152 (58%)] Loss: 616699.875000\n","Train Epoch: 4 [99/152 (65%)] Loss: 624132.125000\n","Train Epoch: 4 [110/152 (72%)] Loss: 592229.187500\n","Train Epoch: 4 [121/152 (80%)] Loss: 636999.125000\n","Train Epoch: 4 [132/152 (87%)] Loss: 627194.312500\n","Train Epoch: 4 [143/152 (94%)] Loss: 613007.250000\n","    learning Rate  : 1e-06\n","    loss           : 608343.144634046\n","    IoU            : 0.08130951970815659\n","    accuracy1      : 0.5\n","    val_loss       : 643266.5357142857\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 2\n","modelNo 2\n","Train Epoch: 5 [0/152 (0%)] Loss: 640145.312500\n","Train Epoch: 5 [11/152 (7%)] Loss: 573843.687500\n","Train Epoch: 5 [22/152 (14%)] Loss: 593823.625000\n","Train Epoch: 5 [33/152 (22%)] Loss: 610030.562500\n","Train Epoch: 5 [44/152 (29%)] Loss: 594152.625000\n","Train Epoch: 5 [55/152 (36%)] Loss: 562099.187500\n","Train Epoch: 5 [66/152 (43%)] Loss: 656659.187500\n","Train Epoch: 5 [77/152 (51%)] Loss: 582600.750000\n","Train Epoch: 5 [88/152 (58%)] Loss: 607175.125000\n","Train Epoch: 5 [99/152 (65%)] Loss: 615635.250000\n","Train Epoch: 5 [110/152 (72%)] Loss: 615670.437500\n","Train Epoch: 5 [121/152 (80%)] Loss: 577170.125000\n","Train Epoch: 5 [132/152 (87%)] Loss: 551013.125000\n","Train Epoch: 5 [143/152 (94%)] Loss: 567645.187500\n","    learning Rate  : 1e-06\n","    loss           : 608280.3772615131\n","    IoU            : 0.08133355528116226\n","    accuracy1      : 0.5\n","    val_loss       : 643318.7594866072\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 3\n","modelNo 2\n","Train Epoch: 6 [0/152 (0%)] Loss: 621715.062500\n","Train Epoch: 6 [11/152 (7%)] Loss: 596378.937500\n","Train Epoch: 6 [22/152 (14%)] Loss: 625661.312500\n","Train Epoch: 6 [33/152 (22%)] Loss: 629467.437500\n","Train Epoch: 6 [44/152 (29%)] Loss: 621062.937500\n","Train Epoch: 6 [55/152 (36%)] Loss: 566018.687500\n","Train Epoch: 6 [66/152 (43%)] Loss: 616481.562500\n","Train Epoch: 6 [77/152 (51%)] Loss: 606174.062500\n","Train Epoch: 6 [88/152 (58%)] Loss: 600486.562500\n","Train Epoch: 6 [99/152 (65%)] Loss: 639844.375000\n","Train Epoch: 6 [110/152 (72%)] Loss: 619569.312500\n","Train Epoch: 6 [121/152 (80%)] Loss: 607286.375000\n","Train Epoch: 6 [132/152 (87%)] Loss: 591580.937500\n","Train Epoch: 6 [143/152 (94%)] Loss: 604237.625000\n","    learning Rate  : 1e-06\n","    loss           : 608228.1926398026\n","    IoU            : 0.08138148486614227\n","    accuracy1      : 0.5\n","    val_loss       : 643148.923828125\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","modelNo 2\n","Train Epoch: 7 [0/152 (0%)] Loss: 621135.312500\n","Train Epoch: 7 [11/152 (7%)] Loss: 607964.187500\n","Train Epoch: 7 [22/152 (14%)] Loss: 633904.875000\n","Train Epoch: 7 [33/152 (22%)] Loss: 633360.875000\n","Train Epoch: 7 [44/152 (29%)] Loss: 638142.250000\n","Train Epoch: 7 [55/152 (36%)] Loss: 631239.625000\n","Train Epoch: 7 [66/152 (43%)] Loss: 581855.062500\n","Train Epoch: 7 [77/152 (51%)] Loss: 623378.500000\n","Train Epoch: 7 [88/152 (58%)] Loss: 603837.437500\n","Train Epoch: 7 [99/152 (65%)] Loss: 644388.687500\n","Train Epoch: 7 [110/152 (72%)] Loss: 657327.250000\n","Train Epoch: 7 [121/152 (80%)] Loss: 606723.062500\n","Train Epoch: 7 [132/152 (87%)] Loss: 624843.500000\n","Train Epoch: 7 [143/152 (94%)] Loss: 615367.812500\n","    learning Rate  : 1e-06\n","    loss           : 607931.1842105263\n","    IoU            : 0.08135350793600082\n","    accuracy1      : 0.5\n","    val_loss       : 642348.8989955357\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","modelNo 2\n","Train Epoch: 8 [0/152 (0%)] Loss: 585321.812500\n","Train Epoch: 8 [11/152 (7%)] Loss: 584445.562500\n","Train Epoch: 8 [22/152 (14%)] Loss: 597127.187500\n","Train Epoch: 8 [33/152 (22%)] Loss: 584126.312500\n","Train Epoch: 8 [44/152 (29%)] Loss: 640130.937500\n","Train Epoch: 8 [55/152 (36%)] Loss: 585378.375000\n","Train Epoch: 8 [66/152 (43%)] Loss: 633944.250000\n","Train Epoch: 8 [77/152 (51%)] Loss: 574380.312500\n","Train Epoch: 8 [88/152 (58%)] Loss: 638399.250000\n","Train Epoch: 8 [99/152 (65%)] Loss: 587996.937500\n","Train Epoch: 8 [110/152 (72%)] Loss: 564792.312500\n","Train Epoch: 8 [121/152 (80%)] Loss: 589602.750000\n","Train Epoch: 8 [132/152 (87%)] Loss: 565271.125000\n","Train Epoch: 8 [143/152 (94%)] Loss: 535984.500000\n","    learning Rate  : 1e-06\n","    loss           : 592414.1260279606\n","    IoU            : 0.08541981875896454\n","    accuracy1      : 0.5176743310121248\n","    val_loss       : 634930.0326450893\n","    val_IoU        : 0.08884136378765106\n","    val_accuracy1  : 0.502642350232077\n","modelNo 2\n","Train Epoch: 9 [0/152 (0%)] Loss: 545199.625000\n","Train Epoch: 9 [11/152 (7%)] Loss: 589819.687500\n","Train Epoch: 9 [22/152 (14%)] Loss: 564665.875000\n","Train Epoch: 9 [33/152 (22%)] Loss: 554446.937500\n","Train Epoch: 9 [44/152 (29%)] Loss: 642033.437500\n","Train Epoch: 9 [55/152 (36%)] Loss: 590759.562500\n","Train Epoch: 9 [66/152 (43%)] Loss: 566680.250000\n","Train Epoch: 9 [77/152 (51%)] Loss: 595009.187500\n","Train Epoch: 9 [88/152 (58%)] Loss: 541041.937500\n","Train Epoch: 9 [99/152 (65%)] Loss: 527275.937500\n","Train Epoch: 9 [110/152 (72%)] Loss: 571046.812500\n","Train Epoch: 9 [121/152 (80%)] Loss: 590949.812500\n","Train Epoch: 9 [132/152 (87%)] Loss: 556632.000000\n","Train Epoch: 9 [143/152 (94%)] Loss: 604858.937500\n","    learning Rate  : 1e-06\n","    loss           : 574945.466899671\n","    IoU            : 0.09291063994169235\n","    accuracy1      : 0.5472611858020858\n","    val_loss       : 649608.5979352678\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 1\n","modelNo 2\n","Train Epoch: 10 [0/152 (0%)] Loss: 584158.500000\n","Train Epoch: 10 [11/152 (7%)] Loss: 639713.187500\n","Train Epoch: 10 [22/152 (14%)] Loss: 583722.062500\n","Train Epoch: 10 [33/152 (22%)] Loss: 600412.687500\n","Train Epoch: 10 [44/152 (29%)] Loss: 610306.937500\n","Train Epoch: 10 [55/152 (36%)] Loss: 580658.500000\n","Train Epoch: 10 [66/152 (43%)] Loss: 595795.250000\n","Train Epoch: 10 [77/152 (51%)] Loss: 555998.187500\n","Train Epoch: 10 [88/152 (58%)] Loss: 610737.750000\n","Train Epoch: 10 [99/152 (65%)] Loss: 621352.562500\n","Train Epoch: 10 [110/152 (72%)] Loss: 625531.250000\n","Train Epoch: 10 [121/152 (80%)] Loss: 636053.937500\n","Train Epoch: 10 [132/152 (87%)] Loss: 617075.562500\n","Train Epoch: 10 [143/152 (94%)] Loss: 590940.750000\n","    learning Rate  : 1e-06\n","    loss           : 608858.3097245066\n","    IoU            : 0.08130946010351181\n","    accuracy1      : 0.5\n","    val_loss       : 643225.5633370535\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 2\n","Saving checkpoint: saved/models/HED/0316_080010/checkpoint-epoch10.pth ...\n","modelNo 2\n","Train Epoch: 11 [0/152 (0%)] Loss: 602531.062500\n","Train Epoch: 11 [11/152 (7%)] Loss: 601464.437500\n","Train Epoch: 11 [22/152 (14%)] Loss: 648452.250000\n","Train Epoch: 11 [33/152 (22%)] Loss: 562142.625000\n","Train Epoch: 11 [44/152 (29%)] Loss: 607192.750000\n","Train Epoch: 11 [55/152 (36%)] Loss: 633763.312500\n","Train Epoch: 11 [66/152 (43%)] Loss: 642780.750000\n","Train Epoch: 11 [77/152 (51%)] Loss: 621189.062500\n","Train Epoch: 11 [88/152 (58%)] Loss: 626090.687500\n","Train Epoch: 11 [99/152 (65%)] Loss: 605947.062500\n","Train Epoch: 11 [110/152 (72%)] Loss: 629134.875000\n","Train Epoch: 11 [121/152 (80%)] Loss: 609620.562500\n","Train Epoch: 11 [132/152 (87%)] Loss: 604426.250000\n","Train Epoch: 11 [143/152 (94%)] Loss: 574350.187500\n","    learning Rate  : 1e-06\n","    loss           : 608424.341796875\n","    IoU            : 0.08135183155536652\n","    accuracy1      : 0.5\n","    val_loss       : 643140.4595424107\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 3\n","modelNo 2\n","Train Epoch: 12 [0/152 (0%)] Loss: 616340.750000\n","Train Epoch: 12 [11/152 (7%)] Loss: 590809.625000\n","Train Epoch: 12 [22/152 (14%)] Loss: 609761.875000\n","Train Epoch: 12 [33/152 (22%)] Loss: 615601.625000\n","Train Epoch: 12 [44/152 (29%)] Loss: 573172.562500\n","Train Epoch: 12 [55/152 (36%)] Loss: 621950.562500\n","Train Epoch: 12 [66/152 (43%)] Loss: 595525.187500\n","Train Epoch: 12 [77/152 (51%)] Loss: 599781.687500\n","Train Epoch: 12 [88/152 (58%)] Loss: 609697.375000\n","Train Epoch: 12 [99/152 (65%)] Loss: 621169.562500\n","Train Epoch: 12 [110/152 (72%)] Loss: 592108.750000\n","Train Epoch: 12 [121/152 (80%)] Loss: 573876.750000\n","Train Epoch: 12 [132/152 (87%)] Loss: 661406.437500\n","Train Epoch: 12 [143/152 (94%)] Loss: 592014.375000\n","    learning Rate  : 1e-06\n","    loss           : 608341.29296875\n","    IoU            : 0.08135320991277695\n","    accuracy1      : 0.5\n","    val_loss       : 643125.8683035715\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 4\n","modelNo 2\n","Train Epoch: 13 [0/152 (0%)] Loss: 581090.062500\n","Train Epoch: 13 [11/152 (7%)] Loss: 604045.500000\n","Train Epoch: 13 [22/152 (14%)] Loss: 621029.125000\n","Train Epoch: 13 [33/152 (22%)] Loss: 614462.125000\n","Train Epoch: 13 [44/152 (29%)] Loss: 625434.000000\n","Train Epoch: 13 [55/152 (36%)] Loss: 607266.062500\n","Train Epoch: 13 [66/152 (43%)] Loss: 588333.375000\n","Train Epoch: 13 [77/152 (51%)] Loss: 666835.937500\n","Train Epoch: 13 [88/152 (58%)] Loss: 626725.875000\n","Train Epoch: 13 [99/152 (65%)] Loss: 634586.687500\n","Train Epoch: 13 [110/152 (72%)] Loss: 595658.562500\n","Train Epoch: 13 [121/152 (80%)] Loss: 635736.687500\n","Train Epoch: 13 [132/152 (87%)] Loss: 624508.062500\n","Train Epoch: 13 [143/152 (94%)] Loss: 574769.437500\n","    learning Rate  : 1e-06\n","    loss           : 608338.8771587171\n","    IoU            : 0.08130139857530594\n","    accuracy1      : 0.5\n","    val_loss       : 643165.2572544643\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 5\n","modelNo 2\n","Train Epoch: 14 [0/152 (0%)] Loss: 563590.875000\n","Train Epoch: 14 [11/152 (7%)] Loss: 650452.062500\n","Train Epoch: 14 [22/152 (14%)] Loss: 618699.562500\n","Train Epoch: 14 [33/152 (22%)] Loss: 610428.250000\n","Train Epoch: 14 [44/152 (29%)] Loss: 590751.062500\n","Train Epoch: 14 [55/152 (36%)] Loss: 628167.375000\n","Train Epoch: 14 [66/152 (43%)] Loss: 625134.562500\n","Train Epoch: 14 [77/152 (51%)] Loss: 606532.562500\n","Train Epoch: 14 [88/152 (58%)] Loss: 557458.062500\n","Train Epoch: 14 [99/152 (65%)] Loss: 605018.687500\n","Train Epoch: 14 [110/152 (72%)] Loss: 601928.750000\n","Train Epoch: 14 [121/152 (80%)] Loss: 606398.437500\n","Train Epoch: 14 [132/152 (87%)] Loss: 603793.312500\n","Train Epoch: 14 [143/152 (94%)] Loss: 602904.687500\n","Epoch    14: reducing learning rate of group 0 to 1.0000e-07.\n","    learning Rate  : 1e-07\n","    loss           : 608323.111225329\n","    IoU            : 0.08132463693618774\n","    accuracy1      : 0.5\n","    val_loss       : 643132.4176897322\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 6\n","modelNo 2\n","Train Epoch: 15 [0/152 (0%)] Loss: 606788.562500\n","Train Epoch: 15 [11/152 (7%)] Loss: 613490.437500\n","Train Epoch: 15 [22/152 (14%)] Loss: 639771.187500\n","Train Epoch: 15 [33/152 (22%)] Loss: 555334.750000\n","Train Epoch: 15 [44/152 (29%)] Loss: 642743.062500\n","Train Epoch: 15 [55/152 (36%)] Loss: 617408.625000\n","Train Epoch: 15 [66/152 (43%)] Loss: 618705.812500\n","Train Epoch: 15 [77/152 (51%)] Loss: 580805.437500\n","Train Epoch: 15 [88/152 (58%)] Loss: 584415.750000\n","Train Epoch: 15 [99/152 (65%)] Loss: 593123.687500\n","Train Epoch: 15 [110/152 (72%)] Loss: 647973.375000\n","Train Epoch: 15 [121/152 (80%)] Loss: 629339.750000\n","Train Epoch: 15 [132/152 (87%)] Loss: 629476.312500\n","Train Epoch: 15 [143/152 (94%)] Loss: 617287.187500\n","    learning Rate  : 1e-07\n","    loss           : 608303.5921052631\n","    IoU            : 0.08135759085416794\n","    accuracy1      : 0.5\n","    val_loss       : 643111.6068638393\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 7\n","modelNo 2\n","Train Epoch: 16 [0/152 (0%)] Loss: 574491.250000\n","Train Epoch: 16 [11/152 (7%)] Loss: 614279.812500\n","Train Epoch: 16 [22/152 (14%)] Loss: 625639.625000\n","Train Epoch: 16 [33/152 (22%)] Loss: 585280.187500\n","Train Epoch: 16 [44/152 (29%)] Loss: 611997.187500\n","Train Epoch: 16 [55/152 (36%)] Loss: 608742.875000\n","Train Epoch: 16 [66/152 (43%)] Loss: 585590.125000\n","Train Epoch: 16 [77/152 (51%)] Loss: 619158.312500\n","Train Epoch: 16 [88/152 (58%)] Loss: 601081.812500\n","Train Epoch: 16 [99/152 (65%)] Loss: 601850.062500\n","Train Epoch: 16 [110/152 (72%)] Loss: 636571.750000\n","Train Epoch: 16 [121/152 (80%)] Loss: 602063.187500\n","Train Epoch: 16 [132/152 (87%)] Loss: 581527.187500\n","Train Epoch: 16 [143/152 (94%)] Loss: 625568.562500\n","    learning Rate  : 1e-07\n","    loss           : 608291.595600329\n","    IoU            : 0.08133302628993988\n","    accuracy1      : 0.5\n","    val_loss       : 643117.3032924107\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 8\n","modelNo 2\n","Train Epoch: 17 [0/152 (0%)] Loss: 589538.875000\n","Train Epoch: 17 [11/152 (7%)] Loss: 606428.312500\n","Train Epoch: 17 [22/152 (14%)] Loss: 628666.062500\n","Train Epoch: 17 [33/152 (22%)] Loss: 637632.062500\n","Train Epoch: 17 [44/152 (29%)] Loss: 605456.562500\n","Train Epoch: 17 [55/152 (36%)] Loss: 629022.875000\n","Train Epoch: 17 [66/152 (43%)] Loss: 594945.375000\n","Train Epoch: 17 [77/152 (51%)] Loss: 620819.187500\n","Train Epoch: 17 [88/152 (58%)] Loss: 587659.187500\n","Train Epoch: 17 [99/152 (65%)] Loss: 589157.937500\n","Train Epoch: 17 [110/152 (72%)] Loss: 611506.375000\n","Train Epoch: 17 [121/152 (80%)] Loss: 640846.062500\n","Train Epoch: 17 [132/152 (87%)] Loss: 592528.812500\n","Train Epoch: 17 [143/152 (94%)] Loss: 612863.937500\n","    learning Rate  : 1e-07\n","    loss           : 608287.2097039474\n","    IoU            : 0.0813412070274353\n","    accuracy1      : 0.5\n","    val_loss       : 643118.5248325893\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 9\n","modelNo 2\n","Train Epoch: 18 [0/152 (0%)] Loss: 586853.687500\n","Train Epoch: 18 [11/152 (7%)] Loss: 587852.250000\n","Train Epoch: 18 [22/152 (14%)] Loss: 633442.687500\n","Train Epoch: 18 [33/152 (22%)] Loss: 624600.687500\n","Train Epoch: 18 [44/152 (29%)] Loss: 650382.812500\n","Train Epoch: 18 [55/152 (36%)] Loss: 653677.625000\n","Train Epoch: 18 [66/152 (43%)] Loss: 605579.562500\n","Train Epoch: 18 [77/152 (51%)] Loss: 645402.312500\n","Train Epoch: 18 [88/152 (58%)] Loss: 653754.250000\n","Train Epoch: 18 [99/152 (65%)] Loss: 582586.250000\n","Train Epoch: 18 [110/152 (72%)] Loss: 607773.500000\n","Train Epoch: 18 [121/152 (80%)] Loss: 588599.562500\n","Train Epoch: 18 [132/152 (87%)] Loss: 566977.687500\n","Train Epoch: 18 [143/152 (94%)] Loss: 644921.250000\n","    learning Rate  : 1e-07\n","    loss           : 608267.3013980263\n","    IoU            : 0.08135664463043213\n","    accuracy1      : 0.5\n","    val_loss       : 643114.9606584822\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 10\n","modelNo 2\n","Train Epoch: 19 [0/152 (0%)] Loss: 643794.312500\n","Train Epoch: 19 [11/152 (7%)] Loss: 600592.937500\n","Train Epoch: 19 [22/152 (14%)] Loss: 579107.187500\n","Train Epoch: 19 [33/152 (22%)] Loss: 632633.750000\n","Train Epoch: 19 [44/152 (29%)] Loss: 602762.187500\n","Train Epoch: 19 [55/152 (36%)] Loss: 585206.437500\n","Train Epoch: 19 [66/152 (43%)] Loss: 597528.812500\n","Train Epoch: 19 [77/152 (51%)] Loss: 636105.562500\n","Train Epoch: 19 [88/152 (58%)] Loss: 646687.750000\n","Train Epoch: 19 [99/152 (65%)] Loss: 629029.687500\n","Train Epoch: 19 [110/152 (72%)] Loss: 614828.375000\n","Train Epoch: 19 [121/152 (80%)] Loss: 634983.625000\n","Train Epoch: 19 [132/152 (87%)] Loss: 628053.000000\n","Train Epoch: 19 [143/152 (94%)] Loss: 598444.875000\n","    learning Rate  : 1e-07\n","    loss           : 608271.3400493421\n","    IoU            : 0.08135788142681122\n","    accuracy1      : 0.5\n","    val_loss       : 643117.0756138393\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 11\n","modelNo 2\n","Train Epoch: 20 [0/152 (0%)] Loss: 598804.375000\n","Train Epoch: 20 [11/152 (7%)] Loss: 562079.125000\n","Train Epoch: 20 [22/152 (14%)] Loss: 605168.062500\n","Train Epoch: 20 [33/152 (22%)] Loss: 585903.062500\n","Train Epoch: 20 [44/152 (29%)] Loss: 631548.187500\n","Train Epoch: 20 [55/152 (36%)] Loss: 560328.937500\n","Train Epoch: 20 [66/152 (43%)] Loss: 615707.375000\n","Train Epoch: 20 [77/152 (51%)] Loss: 642822.812500\n","Train Epoch: 20 [88/152 (58%)] Loss: 579000.375000\n","Train Epoch: 20 [99/152 (65%)] Loss: 632451.125000\n","Train Epoch: 20 [110/152 (72%)] Loss: 607616.250000\n","Train Epoch: 20 [121/152 (80%)] Loss: 592614.375000\n","Train Epoch: 20 [132/152 (87%)] Loss: 597783.750000\n","Train Epoch: 20 [143/152 (94%)] Loss: 617607.875000\n","Epoch    20: reducing learning rate of group 0 to 1.0000e-08.\n","    learning Rate  : 1e-08\n","    loss           : 608291.5524259869\n","    IoU            : 0.081329345703125\n","    accuracy1      : 0.5\n","    val_loss       : 643115.7603236607\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 12\n","Saving checkpoint: saved/models/HED/0316_080010/checkpoint-epoch20.pth ...\n","modelNo 2\n","Train Epoch: 21 [0/152 (0%)] Loss: 609178.875000\n","Train Epoch: 21 [11/152 (7%)] Loss: 584818.562500\n","Train Epoch: 21 [22/152 (14%)] Loss: 613248.812500\n","Train Epoch: 21 [33/152 (22%)] Loss: 588080.187500\n","Train Epoch: 21 [44/152 (29%)] Loss: 634529.875000\n","Train Epoch: 21 [55/152 (36%)] Loss: 598109.562500\n","Train Epoch: 21 [66/152 (43%)] Loss: 639703.812500\n","Train Epoch: 21 [77/152 (51%)] Loss: 629117.812500\n","Train Epoch: 21 [88/152 (58%)] Loss: 612576.625000\n","Train Epoch: 21 [99/152 (65%)] Loss: 616559.562500\n","Train Epoch: 21 [110/152 (72%)] Loss: 616121.937500\n","Train Epoch: 21 [121/152 (80%)] Loss: 585987.500000\n","Train Epoch: 21 [132/152 (87%)] Loss: 622229.812500\n","Train Epoch: 21 [143/152 (94%)] Loss: 660221.875000\n","    learning Rate  : 1e-08\n","    loss           : 608287.8140419408\n","    IoU            : 0.08132889121770859\n","    accuracy1      : 0.5\n","    val_loss       : 643115.7977120535\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 13\n","modelNo 2\n","Train Epoch: 22 [0/152 (0%)] Loss: 607552.500000\n","Train Epoch: 22 [11/152 (7%)] Loss: 641011.062500\n","Train Epoch: 22 [22/152 (14%)] Loss: 625470.062500\n","Train Epoch: 22 [33/152 (22%)] Loss: 639882.312500\n","Train Epoch: 22 [44/152 (29%)] Loss: 644273.750000\n","Train Epoch: 22 [55/152 (36%)] Loss: 523865.125000\n","Train Epoch: 22 [66/152 (43%)] Loss: 612520.062500\n","Train Epoch: 22 [77/152 (51%)] Loss: 571095.312500\n","Train Epoch: 22 [88/152 (58%)] Loss: 618476.562500\n","Train Epoch: 22 [99/152 (65%)] Loss: 600249.000000\n","Train Epoch: 22 [110/152 (72%)] Loss: 636167.187500\n","Train Epoch: 22 [121/152 (80%)] Loss: 621531.750000\n","Train Epoch: 22 [132/152 (87%)] Loss: 578003.437500\n","Train Epoch: 22 [143/152 (94%)] Loss: 605994.812500\n","    learning Rate  : 1e-08\n","    loss           : 608285.3046875\n","    IoU            : 0.08131870627403259\n","    accuracy1      : 0.5\n","    val_loss       : 643114.0837053572\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 14\n","modelNo 2\n","Train Epoch: 23 [0/152 (0%)] Loss: 601163.375000\n","Train Epoch: 23 [11/152 (7%)] Loss: 577417.562500\n","Train Epoch: 23 [22/152 (14%)] Loss: 548771.875000\n","Train Epoch: 23 [33/152 (22%)] Loss: 629139.937500\n","Train Epoch: 23 [44/152 (29%)] Loss: 604533.312500\n","Train Epoch: 23 [55/152 (36%)] Loss: 608398.875000\n","Train Epoch: 23 [66/152 (43%)] Loss: 589389.750000\n","Train Epoch: 23 [77/152 (51%)] Loss: 605311.875000\n","Train Epoch: 23 [88/152 (58%)] Loss: 590860.625000\n","Train Epoch: 23 [99/152 (65%)] Loss: 633591.750000\n","Train Epoch: 23 [110/152 (72%)] Loss: 603054.437500\n","Train Epoch: 23 [121/152 (80%)] Loss: 620997.812500\n","Train Epoch: 23 [132/152 (87%)] Loss: 612303.125000\n","Train Epoch: 23 [143/152 (94%)] Loss: 580733.062500\n","    learning Rate  : 1e-08\n","    loss           : 608290.2921463816\n","    IoU            : 0.0813446119427681\n","    accuracy1      : 0.5\n","    val_loss       : 643115.01171875\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 15\n","modelNo 2\n","Train Epoch: 24 [0/152 (0%)] Loss: 610873.687500\n","Train Epoch: 24 [11/152 (7%)] Loss: 587236.437500\n","Train Epoch: 24 [22/152 (14%)] Loss: 616124.062500\n","Train Epoch: 24 [33/152 (22%)] Loss: 644485.875000\n","Train Epoch: 24 [44/152 (29%)] Loss: 612948.062500\n","Train Epoch: 24 [55/152 (36%)] Loss: 615485.500000\n","Train Epoch: 24 [66/152 (43%)] Loss: 589530.937500\n","Train Epoch: 24 [77/152 (51%)] Loss: 573228.937500\n","Train Epoch: 24 [88/152 (58%)] Loss: 598403.687500\n","Train Epoch: 24 [99/152 (65%)] Loss: 606394.562500\n","Train Epoch: 24 [110/152 (72%)] Loss: 578212.687500\n","Train Epoch: 24 [121/152 (80%)] Loss: 598586.062500\n","Train Epoch: 24 [132/152 (87%)] Loss: 598914.875000\n","Train Epoch: 24 [143/152 (94%)] Loss: 619001.125000\n","    learning Rate  : 1e-08\n","    loss           : 608273.1551192434\n","    IoU            : 0.08135019242763519\n","    accuracy1      : 0.5\n","    val_loss       : 643115.0033482143\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 16\n","modelNo 2\n","Train Epoch: 25 [0/152 (0%)] Loss: 643384.687500\n","Train Epoch: 25 [11/152 (7%)] Loss: 587086.375000\n","Train Epoch: 25 [22/152 (14%)] Loss: 569428.812500\n","Train Epoch: 25 [33/152 (22%)] Loss: 610225.437500\n","Train Epoch: 25 [44/152 (29%)] Loss: 621942.187500\n","Train Epoch: 25 [55/152 (36%)] Loss: 630313.312500\n","Train Epoch: 25 [66/152 (43%)] Loss: 615930.250000\n","Train Epoch: 25 [77/152 (51%)] Loss: 635895.562500\n","Train Epoch: 25 [88/152 (58%)] Loss: 619737.812500\n","Train Epoch: 25 [99/152 (65%)] Loss: 575640.812500\n","Train Epoch: 25 [110/152 (72%)] Loss: 629618.062500\n","Train Epoch: 25 [121/152 (80%)] Loss: 627826.750000\n","Train Epoch: 25 [132/152 (87%)] Loss: 609035.625000\n","Train Epoch: 25 [143/152 (94%)] Loss: 615255.312500\n","    learning Rate  : 1e-08\n","    loss           : 608277.7845394737\n","    IoU            : 0.08134760707616806\n","    accuracy1      : 0.5\n","    val_loss       : 643115.0736607143\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 17\n","modelNo 2\n","Train Epoch: 26 [0/152 (0%)] Loss: 638994.750000\n","Train Epoch: 26 [11/152 (7%)] Loss: 630650.437500\n","Train Epoch: 26 [22/152 (14%)] Loss: 674284.062500\n","Train Epoch: 26 [33/152 (22%)] Loss: 572353.312500\n","Train Epoch: 26 [44/152 (29%)] Loss: 586678.687500\n","Train Epoch: 26 [55/152 (36%)] Loss: 658217.562500\n","Train Epoch: 26 [66/152 (43%)] Loss: 587193.625000\n","Train Epoch: 26 [77/152 (51%)] Loss: 630659.375000\n","Train Epoch: 26 [88/152 (58%)] Loss: 631723.687500\n","Train Epoch: 26 [99/152 (65%)] Loss: 607838.750000\n","Train Epoch: 26 [110/152 (72%)] Loss: 647812.187500\n","Train Epoch: 26 [121/152 (80%)] Loss: 608066.062500\n","Train Epoch: 26 [132/152 (87%)] Loss: 589495.062500\n","Train Epoch: 26 [143/152 (94%)] Loss: 593649.187500\n","    learning Rate  : 1e-08\n","    loss           : 608274.1436060856\n","    IoU            : 0.08132164180278778\n","    accuracy1      : 0.5\n","    val_loss       : 643115.9857700893\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 18\n","modelNo 2\n","Train Epoch: 27 [0/152 (0%)] Loss: 584468.437500\n","Train Epoch: 27 [11/152 (7%)] Loss: 634135.562500\n","Train Epoch: 27 [22/152 (14%)] Loss: 630897.750000\n","Train Epoch: 27 [33/152 (22%)] Loss: 624372.125000\n","Train Epoch: 27 [44/152 (29%)] Loss: 617728.875000\n","Train Epoch: 27 [55/152 (36%)] Loss: 643954.625000\n","Train Epoch: 27 [66/152 (43%)] Loss: 627430.562500\n","Train Epoch: 27 [77/152 (51%)] Loss: 577610.375000\n","Train Epoch: 27 [88/152 (58%)] Loss: 653557.125000\n","Train Epoch: 27 [99/152 (65%)] Loss: 562075.625000\n","Train Epoch: 27 [110/152 (72%)] Loss: 619232.875000\n","Train Epoch: 27 [121/152 (80%)] Loss: 619367.187500\n","Train Epoch: 27 [132/152 (87%)] Loss: 590911.187500\n","Train Epoch: 27 [143/152 (94%)] Loss: 620217.625000\n","    learning Rate  : 1e-08\n","    loss           : 608286.3376850329\n","    IoU            : 0.0813421681523323\n","    accuracy1      : 0.5\n","    val_loss       : 643114.2781808035\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 19\n","modelNo 2\n","Train Epoch: 28 [0/152 (0%)] Loss: 618578.312500\n","Train Epoch: 28 [11/152 (7%)] Loss: 628562.937500\n","Train Epoch: 28 [22/152 (14%)] Loss: 587458.312500\n","Train Epoch: 28 [33/152 (22%)] Loss: 650858.437500\n","Train Epoch: 28 [44/152 (29%)] Loss: 667002.062500\n","Train Epoch: 28 [55/152 (36%)] Loss: 626479.375000\n","Train Epoch: 28 [66/152 (43%)] Loss: 623840.937500\n","Train Epoch: 28 [77/152 (51%)] Loss: 612580.062500\n","Train Epoch: 28 [88/152 (58%)] Loss: 607952.437500\n","Train Epoch: 28 [99/152 (65%)] Loss: 590599.562500\n","Train Epoch: 28 [110/152 (72%)] Loss: 573698.687500\n","Train Epoch: 28 [121/152 (80%)] Loss: 594300.312500\n","Train Epoch: 28 [132/152 (87%)] Loss: 580648.000000\n","Train Epoch: 28 [143/152 (94%)] Loss: 583808.187500\n","    learning Rate  : 1e-08\n","    loss           : 608289.6027960526\n","    IoU            : 0.08136709779500961\n","    accuracy1      : 0.5\n","    val_loss       : 643114.4963727678\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 20\n","modelNo 2\n","Train Epoch: 29 [0/152 (0%)] Loss: 621377.875000\n","Train Epoch: 29 [11/152 (7%)] Loss: 679765.812500\n","Train Epoch: 29 [22/152 (14%)] Loss: 634786.562500\n","Train Epoch: 29 [33/152 (22%)] Loss: 610867.312500\n","Train Epoch: 29 [44/152 (29%)] Loss: 608508.062500\n","Train Epoch: 29 [55/152 (36%)] Loss: 612300.500000\n","Train Epoch: 29 [66/152 (43%)] Loss: 596894.500000\n","Train Epoch: 29 [77/152 (51%)] Loss: 648565.312500\n","Train Epoch: 29 [88/152 (58%)] Loss: 603665.687500\n","Train Epoch: 29 [99/152 (65%)] Loss: 625576.250000\n","Train Epoch: 29 [110/152 (72%)] Loss: 608019.062500\n","Train Epoch: 29 [121/152 (80%)] Loss: 665192.625000\n","Train Epoch: 29 [132/152 (87%)] Loss: 586270.687500\n","Train Epoch: 29 [143/152 (94%)] Loss: 642445.562500\n","    learning Rate  : 1e-08\n","    loss           : 608287.5942639803\n","    IoU            : 0.0813162699341774\n","    accuracy1      : 0.5\n","    val_loss       : 643114.1478794643\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 21\n","modelNo 2\n","Train Epoch: 30 [0/152 (0%)] Loss: 605113.312500\n","Train Epoch: 30 [11/152 (7%)] Loss: 617988.187500\n","Train Epoch: 30 [22/152 (14%)] Loss: 592627.312500\n","Train Epoch: 30 [33/152 (22%)] Loss: 566848.750000\n","Train Epoch: 30 [44/152 (29%)] Loss: 616087.125000\n","Train Epoch: 30 [55/152 (36%)] Loss: 591602.312500\n","Train Epoch: 30 [66/152 (43%)] Loss: 633202.687500\n","Train Epoch: 30 [77/152 (51%)] Loss: 577742.312500\n","Train Epoch: 30 [88/152 (58%)] Loss: 628615.187500\n","Train Epoch: 30 [99/152 (65%)] Loss: 557054.250000\n","Train Epoch: 30 [110/152 (72%)] Loss: 604919.437500\n","Train Epoch: 30 [121/152 (80%)] Loss: 626686.312500\n","Train Epoch: 30 [132/152 (87%)] Loss: 633903.125000\n","Train Epoch: 30 [143/152 (94%)] Loss: 611461.500000\n","    learning Rate  : 1e-08\n","    loss           : 608281.2391036184\n","    IoU            : 0.08134110271930695\n","    accuracy1      : 0.5\n","    val_loss       : 643114.11328125\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 22\n","Saving checkpoint: saved/models/HED/0316_080010/checkpoint-epoch30.pth ...\n","modelNo 2\n","Train Epoch: 31 [0/152 (0%)] Loss: 591762.875000\n","Train Epoch: 31 [11/152 (7%)] Loss: 645978.687500\n","Train Epoch: 31 [22/152 (14%)] Loss: 635724.562500\n","Train Epoch: 31 [33/152 (22%)] Loss: 607455.437500\n","Train Epoch: 31 [44/152 (29%)] Loss: 614017.062500\n","Train Epoch: 31 [55/152 (36%)] Loss: 608805.375000\n","Train Epoch: 31 [66/152 (43%)] Loss: 563444.187500\n","Train Epoch: 31 [77/152 (51%)] Loss: 580093.562500\n","Train Epoch: 31 [88/152 (58%)] Loss: 644662.125000\n","Train Epoch: 31 [99/152 (65%)] Loss: 660827.250000\n","Train Epoch: 31 [110/152 (72%)] Loss: 616259.375000\n","Train Epoch: 31 [121/152 (80%)] Loss: 632716.937500\n","Train Epoch: 31 [132/152 (87%)] Loss: 617189.062500\n","Train Epoch: 31 [143/152 (94%)] Loss: 644944.312500\n","    learning Rate  : 1e-08\n","    loss           : 608294.2086759869\n","    IoU            : 0.08135409653186798\n","    accuracy1      : 0.5\n","    val_loss       : 643113.681640625\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 23\n","modelNo 2\n","Train Epoch: 32 [0/152 (0%)] Loss: 572469.875000\n","Train Epoch: 32 [11/152 (7%)] Loss: 604802.625000\n","Train Epoch: 32 [22/152 (14%)] Loss: 606390.187500\n","Train Epoch: 32 [33/152 (22%)] Loss: 604473.875000\n","Train Epoch: 32 [44/152 (29%)] Loss: 610405.312500\n","Train Epoch: 32 [55/152 (36%)] Loss: 595895.000000\n","Train Epoch: 32 [66/152 (43%)] Loss: 598470.000000\n","Train Epoch: 32 [77/152 (51%)] Loss: 629254.812500\n","Train Epoch: 32 [88/152 (58%)] Loss: 567598.625000\n","Train Epoch: 32 [99/152 (65%)] Loss: 627691.750000\n","Train Epoch: 32 [110/152 (72%)] Loss: 637998.812500\n","Train Epoch: 32 [121/152 (80%)] Loss: 661650.750000\n","Train Epoch: 32 [132/152 (87%)] Loss: 611907.312500\n","Train Epoch: 32 [143/152 (94%)] Loss: 611396.812500\n","    learning Rate  : 1e-08\n","    loss           : 608254.9396587171\n","    IoU            : 0.08133357018232346\n","    accuracy1      : 0.5\n","    val_loss       : 643115.3716517857\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 24\n","modelNo 2\n","Train Epoch: 33 [0/152 (0%)] Loss: 578217.062500\n","Train Epoch: 33 [11/152 (7%)] Loss: 613821.750000\n","Train Epoch: 33 [22/152 (14%)] Loss: 654885.187500\n","Train Epoch: 33 [33/152 (22%)] Loss: 650386.812500\n","Train Epoch: 33 [44/152 (29%)] Loss: 631299.687500\n","Train Epoch: 33 [55/152 (36%)] Loss: 598847.562500\n","Train Epoch: 33 [66/152 (43%)] Loss: 605206.875000\n","Train Epoch: 33 [77/152 (51%)] Loss: 587699.437500\n","Train Epoch: 33 [88/152 (58%)] Loss: 641048.562500\n","Train Epoch: 33 [99/152 (65%)] Loss: 608103.187500\n","Train Epoch: 33 [110/152 (72%)] Loss: 593769.062500\n","Train Epoch: 33 [121/152 (80%)] Loss: 539411.750000\n","Train Epoch: 33 [132/152 (87%)] Loss: 626881.437500\n","Train Epoch: 33 [143/152 (94%)] Loss: 649585.687500\n","    learning Rate  : 1e-08\n","    loss           : 608299.953227796\n","    IoU            : 0.08133605122566223\n","    accuracy1      : 0.5\n","    val_loss       : 643116.4642857143\n","    val_IoU        : 0.08838258683681488\n","    val_accuracy1  : 0.5\n","early_stop count: 25\n","modelNo 2\n","Train Epoch: 34 [0/152 (0%)] Loss: 595537.750000\n","Train Epoch: 34 [11/152 (7%)] Loss: 598980.062500\n","Traceback (most recent call last):\n","  File \"train.py\", line 72, in <module>\n","    main(config)\n","  File \"train.py\", line 53, in main\n","    trainer.train()\n","  File \"/content/drive/My Drive/Earthquake/Earthquake6/base/base_trainer.py\", line 82, in train\n","    result = self._train_epoch(epoch)\n","  File \"/content/drive/My Drive/Earthquake/Earthquake6/trainer/trainer.py\", line 61, in _train_epoch\n","    outputs = self.model(images)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/drive/My Drive/Earthquake/Earthquake6/model/model.py\", line 272, in forward\n","    conv5_1 = self.dropout(self.relu(self.conv5_1(pool4)))\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 345, in forward\n","    return self.conv2d_forward(input, self.weight)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 342, in conv2d_forward\n","    self.padding, self.dilation, self.groups)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F9hVIHWlLlkC","colab_type":"code","colab":{}},"source":["!python test.py --config config0.json --resume saved/models/Unet/0315_104258/checkpoint-epoch20.pth"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8tWsp71AMBuu","colab_type":"code","colab":{}},"source":["!python save_predicted_picture.py --config config0.json --resume saved/models/Unet/0315_104258/checkpoint-epoch20.pth "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xbN1rJArKO4F","colab_type":"code","outputId":"34cd77f6-0abe-4005-f487-96f38a2a205d","executionInfo":{"status":"ok","timestamp":1584260945282,"user_tz":-480,"elapsed":15037,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!tensorboard --logdir saved/log/ \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorBoard 1.15.0 at http://127.0.0.1:6007/ (Press CTRL+C to quit)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eo3y_BeYS1a_","colab_type":"code","outputId":"367c3e6e-deb2-464c-846b-1862a5266717","executionInfo":{"status":"ok","timestamp":1584260792287,"user_tz":-480,"elapsed":15422,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-03-15 08:26:20--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.238.178.61, 34.226.145.86, 3.228.72.85, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.238.178.61|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   0%[                    ]  91.31K   359KB/s               \r        ngrok-stabl   6%[>                   ] 887.88K  1.70MB/s               \r       ngrok-stable  43%[=======>            ]   5.74M  7.49MB/s               \r      ngrok-stable-  92%[=================>  ]  12.15M  11.9MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  12.8MB/s    in 1.0s    \n","\n","2020-03-15 08:26:21 (12.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8tVt7QYgTeIE","colab_type":"code","outputId":"62f0ec1f-71bd-430d-87b4-ce95c21de890","executionInfo":{"status":"ok","timestamp":1584260843264,"user_tz":-480,"elapsed":7569,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["!pip install tensorboardcolab"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sm7chJXQTl0f","colab_type":"code","outputId":"7e9706de-1900-416b-c431-c9211d3b3572","executionInfo":{"status":"ok","timestamp":1584260894588,"user_tz":-480,"elapsed":27287,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":148}},"source":["from tensorboardcolab import TensorBoardColab\n","tbc=TensorBoardColab()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://cf2af8ca.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uy-_OYdDT55U","colab_type":"code","outputId":"f1989cac-6b4a-46f0-8dd3-14f63dda2f5e","executionInfo":{"status":"ok","timestamp":1584261290279,"user_tz":-480,"elapsed":18689,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["from tensorboardcolab import TensorBoardColab\n","tbc=TensorBoardColab()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://0891421b.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rttJOmZsUZbY","colab_type":"code","colab":{}},"source":["LOG_DIR = '/content/drive/My Drive/Earthquake/Earthquake6/saved/log'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hBlT9CRPUcPO","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"24i6Pk62Uftm","colab_type":"code","outputId":"7400ffe1-da6b-4b66-aa32-c2696b5a8d44","executionInfo":{"status":"ok","timestamp":1584261625053,"user_tz":-480,"elapsed":5902,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["https://0891421b.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gtHDcaa0_dwy","colab_type":"code","outputId":"9ee51001-425a-4dac-ec26-10ee0650edb0","executionInfo":{"status":"ok","timestamp":1584360917712,"user_tz":-480,"elapsed":3881,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["!apt install unzip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","unzip is already the newest version (6.0-21ubuntu1).\n","0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y4uOd7v6HuiX","colab_type":"code","outputId":"32f246de-61b6-4bf3-9b69-e63d0afbedb7","executionInfo":{"status":"ok","timestamp":1584360960566,"user_tz":-480,"elapsed":22197,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["!unzip  'Copy of seistest.zip' -d '/content/drive/My Drive/original_data/1'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Archive:  Copy of seistest.zip\n","  inflating: /content/drive/My Drive/original_data/1/seistest.npy  error:  zipfile read error\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9xzbJhVjOWLf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"ed7a7dd3-d636-4d1d-87ff-1d91e6c98352","executionInfo":{"status":"ok","timestamp":1584461774985,"user_tz":-480,"elapsed":118967,"user":{"displayName":"Yuan Wang","photoUrl":"","userId":"17198664945483720848"}}},"source":["from google.colab import files\n","files.download('Copy of seistrain.zip')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["----------------------------------------\n","Exception happened during processing of request from ('::ffff:127.0.0.1', 41392, 0, 0)\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n","    self.process_request(request, client_address)\n","  File \"/usr/lib/python3.6/socketserver.py\", line 351, in process_request\n","    self.finish_request(request, client_address)\n","  File \"/usr/lib/python3.6/socketserver.py\", line 364, in finish_request\n","    self.RequestHandlerClass(request, client_address, self)\n","  File \"/usr/lib/python3.6/socketserver.py\", line 724, in __init__\n","    self.handle()\n","  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n","    self.handle_one_request()\n","  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n","    method()\n","  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n","    self.copyfile(f, self.wfile)\n","  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n","    shutil.copyfileobj(source, outputfile)\n","  File \"/usr/lib/python3.6/shutil.py\", line 79, in copyfileobj\n","    buf = fsrc.read(length)\n","OSError: [Errno 5] Input/output error\n","----------------------------------------\n"],"name":"stderr"}]}]}