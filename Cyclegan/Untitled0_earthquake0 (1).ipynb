{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled0_earthquake0.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "1FpX_5NrwHhzwGI1cRJdxgzHccirzAagL",
   "authorship_tag": "ABX9TyOL9Jcdy8nfnHS8UntXJeMA"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "v4ElX7sSPv2U",
    "colab_type": "code",
    "outputId": "617840ad-5a10-47f4-daa2-32e83cc5bc67",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588336653227,
     "user_tz": -480,
     "elapsed": 1323,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "source": [
    "#z\n",
    "cd /content/drive/My Drive/Earthquake7"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Earthquake7\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NVNZnEdHL50A",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir saved/log/\n",
    "\n",
    "# # # # # 加载一次后，如果要重新加载，就需要使用reload方法\n",
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir saved/log/"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qd2yBKWTXcXE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_G1Qrx_Xch1",
    "colab_type": "text"
   },
   "source": [
    "preprocessing: transfer npy to png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEqWYXw9YAT8",
    "colab_type": "text"
   },
   "source": [
    "1.dataset A seismic picture"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uwb5BsoUX0NP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from functions import *\n",
    "# path = '/content/drive/My Drive/datasets2/subGSBxl_t_il.npy'\n",
    "path=\"/content/drive/My Drive/seis_sub_350IL_500t_1200XL.npy\"\n",
    "import numpy as np\n",
    "data =np.load(path)\n",
    "length=data.shape[0]\n",
    "save_path= '/content/drive/My Drive/style_data/RGBA_datasetA'\n",
    "import os\n",
    "if not os.path.exists(save_path):\n",
    "  os.makedirs(save_path)\n",
    "  print(save_path)\n",
    "import matplotlib.image as mp\n",
    "from PIL import Image\n",
    "\n",
    "for index in range(0,350,1):\n",
    "    data1=data[index]\n",
    "    # column = data1[:,-1]\n",
    "    # data1=np.column_stack((data1,column))\n",
    "    # data1=np.expand_dims(data1,axis=0)\n",
    "    print(data1.shape)\n",
    "    mp.imsave('{}/{}.png'.format(save_path, index),data1)\n",
    "    # np.save(os.path.join(save_path, \"{}\".format(index)), data1) "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb6fvPppYF5S",
    "colab_type": "text"
   },
   "source": [
    "2.datasetB seismic picture\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Am0VNUpBX-qe",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "outputId": "ded66a7e-fb55-407e-e136-fb3e1ebfcdcb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588337022453,
     "user_tz": -480,
     "elapsed": 2137,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    }
   },
   "source": [
    "from functions import *\n",
    "path = '/content/drive/My Drive/datasets2/subGSBxl_t_il.npy'\n",
    "# path=\"/content/drive/My Drive/seis_sub_350IL_500t_1200XL.npy\"\n",
    "import numpy as np\n",
    "data =np.load(path)\n",
    "length=data.shape[0]\n",
    "save_path= '/content/drive/My Drive/style_data/RGBA_datasetB'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(save_path):\n",
    "  os.makedirs(save_path)\n",
    "  print(save_path)\n",
    "import matplotlib.image as mp\n",
    "\n",
    "for index in range(188,200,1):\n",
    "    data1=data[index]\n",
    "    column = data1[:,-1]\n",
    "    data1=np.column_stack((data1,column))\n",
    "\n",
    "    # data1=np.expand_dims(data1,axis=0)\n",
    "    print(data1.shape)\n",
    "\n",
    "    # print(img.shape)\n",
    "    # img.save('{}/{}.png'.format(save_path, index))\n",
    "    mp.imsave('{}/{}.png'.format(save_path, index),data1)\n"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n",
      "(100, 484)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_6ajyyNX0oS",
    "colab_type": "text"
   },
   "source": [
    "transfer png to gray_png   x4"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sfGcpOyfXs_E",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from functions import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "save_path= '/content/drive/My Drive/style_data2/trainA'\n",
    "load_path='/content/drive/My Drive/style_data/RGBA_datasetA'\n",
    "# save_path= '/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/datasets/430/testA'\n",
    "# load_path='/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/datasets/earthquake429/testA'\n",
    "import os\n",
    "if not os.path.exists(load_path):\n",
    "  os.makedirs(load_path)\n",
    "  print(load_path)\n",
    "import matplotlib.image as mp\n",
    "from PIL import Image\n",
    "# 0-15 100-115 200-215 300-315\n",
    "# for index in range(0,15,1):\n",
    "\n",
    "#     # data1=np.expand_dims(data1,axis=0)\n",
    "#     img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "#     img = img.convert('L')\n",
    "#     # print(img.shape)\n",
    "#     img.save('{}/{}.png'.format(save_path, index))\n",
    "  \n",
    "# for index in range(100,115,1):\n",
    "\n",
    "#     # data1=np.expand_dims(data1,axis=0)\n",
    "#     img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "#     img = img.convert('L')\n",
    "#     # print(img.shape)\n",
    "#     img.save('{}/{}.png'.format(save_path, index))\n",
    "  \n",
    "for index in range(222,222+64,1):\n",
    "\n",
    "    # data1=np.expand_dims(data1,axis=0)\n",
    "    img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "    img = img.convert('L')\n",
    "    # print(img.shape)\n",
    "    img.save('{}/{}.png'.format(save_path, index))\n",
    "  \n",
    "# for index in range(300,315,1):\n",
    "\n",
    "#     # data1=np.expand_dims(data1,axis=0)\n",
    "#     img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "#     img = img.convert('L')\n",
    "#     # print(img.shape)\n",
    "#     img.save('{}/{}.png'.format(save_path, index))\n",
    "  "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glm8y_-bi05-",
    "colab_type": "text"
   },
   "source": [
    "trainB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CS-1Go4aiycN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from functions import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "save_path= '/content/drive/My Drive/style_data2/trainB'\n",
    "load_path='/content/drive/My Drive/style_data/RGBA_datasetB'\n",
    "# save_path= '/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/datasets/430/testA'\n",
    "# load_path='/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/datasets/earthquake429/testA'\n",
    "import matplotlib.image as mp\n",
    "from PIL import Image\n",
    "# 300-315 400-415 500-515 600-615\n",
    "for index in range(188,188+64,1):\n",
    "\n",
    "    # data1=np.expand_dims(data1,axis=0)\n",
    "    img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "    img = img.convert('L')\n",
    "    # print(img.shape)\n",
    "    img.save('{}/{}.png'.format(save_path, index))\n",
    "# for index in range(400,415,1):\n",
    "\n",
    "#     # data1=np.expand_dims(data1,axis=0)\n",
    "#     img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "#     img = img.convert('L')\n",
    "#     # print(img.shape)\n",
    "#     img.save('{}/{}.png'.format(save_path, index))\n",
    "# for index in range(500,515,1):\n",
    "\n",
    "#     # data1=np.expand_dims(data1,axis=0)\n",
    "#     img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "#     img = img.convert('L')\n",
    "#     # print(img.shape)\n",
    "#     img.save('{}/{}.png'.format(save_path, index))\n",
    "# for index in range(600,615,1):\n",
    "\n",
    "#     # data1=np.expand_dims(data1,axis=0)\n",
    "#     img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "#     img = img.convert('L')\n",
    "#     # print(img.shape)\n",
    "#     img.save('{}/{}.png'.format(save_path, index))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oe-XdXOri0W0",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "testA\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kuCbbD7niysJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from functions import *\n",
    "\n",
    "import numpy as np\n",
    "data =np.load(path)\n",
    "length=data.shape[0]\n",
    "save_path= '/content/drive/My Drive/style_data2/testA'\n",
    "load_path='/content/drive/My Drive/style_data/RGBA_datasetA'\n",
    "# save_path= '/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/datasets/430/testA'\n",
    "# load_path='/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/datasets/earthquake429/testA'\n",
    "import matplotlib.image as mp\n",
    "from PIL import Image\n",
    "\n",
    "for index in range(0,350,1):\n",
    "\n",
    "    # data1=np.expand_dims(data1,axis=0)\n",
    "    img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "    img = img.convert('L')\n",
    "    # print(img.shape)\n",
    "    img.save('{}/{}.png'.format(save_path, index))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEDebLQQi1w-",
    "colab_type": "text"
   },
   "source": [
    "testB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NqaKzrk4iy0U",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from functions import *\n",
    "\n",
    "import numpy as np\n",
    "data =np.load(path)\n",
    "length=data.shape[0]\n",
    "save_path= '/content/drive/My Drive/style_data2/testB'\n",
    "load_path='/content/drive/My Drive/style_data/RGBA_datasetB'\n",
    "# save_path= '/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/datasets/430/testA'\n",
    "# load_path='/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/datasets/earthquake429/testA'\n",
    "import matplotlib.image as mp\n",
    "from PIL import Image\n",
    "\n",
    "for index in range(188,199,1):\n",
    "\n",
    "    # data1=np.expand_dims(data1,axis=0)\n",
    "    img=Image.open('{}/{}.png'.format(load_path, index))\n",
    "    img = img.convert('L')\n",
    "    # print(img.shape)\n",
    "    img.save('{}/{}.png'.format(save_path, index))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pksoGi-DXhx8",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zK8lg3tkXck7",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQnucuk4Xcpf",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tn5zzG-tXcuO",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1MANMndXcs1",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKbyzGkhXcn6",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vm0RUu36UjVT",
    "colab_type": "text"
   },
   "source": [
    "Step1.style transfer style A to style B  (cyclegan)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_lUH_SdSUjdt",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "6eef38a6-0db7-4c1f-fd4f-b8eb6218bedf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588339056570,
     "user_tz": -480,
     "elapsed": 714,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    }
   },
   "source": [
    "cd /content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ndVXTPkUmnBc",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "outputId": "b9b61924-550e-4237-e513-a26ae1cc27bd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588339063295,
     "user_tz": -480,
     "elapsed": 5669,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    }
   },
   "source": [
    "!pi!p install -r requirements.txt"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.5.0+cu101)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.6.0+cu101)\n",
      "Requirement already satisfied: dominate>=2.3.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.5.1)\n",
      "Requirement already satisfied: visdom>=0.1.8.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.1.8.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->-r requirements.txt (line 1)) (1.18.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: torchfile in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.25)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (19.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.21.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.12.0)\n",
      "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (4.5.3)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (0.57.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.6/dist-packages (from jsonpatch->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.8)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e-O47jaOWnEc",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "106174dd-5ef7-4541-88d8-b6f01eadbd61"
   },
   "source": [
    "!python train.py --dataroot  '/content/drive/My Drive/style_data2'  --name 4301_64 --model cycle_gan  --n_epochs 5000 --batch_size 6 --input_nc 1 --output_nc 1 --save_epoch_freq 40 "
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 6                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /content/drive/My Drive/style_data2\t[default: None]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "                 n_epochs: 5000                          \t[default: 100]\n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: 4301_64                       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 40                            \t[default: 5]\n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "The number of training images = 64\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.366 M\n",
      "[Network G_B] Total number of parameters : 11.366 M\n",
      "[Network D_A] Total number of parameters : 2.763 M\n",
      "[Network D_B] Total number of parameters : 2.763 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory ./checkpoints/4301_64/web...\n",
      "End of epoch 1 / 5100 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 2 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 3 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 4 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 36, time: 0.267, data: 0.567) D_A: 0.300 G_A: 0.591 cycle_A: 1.227 idt_A: 0.564 D_B: 0.412 G_B: 0.760 cycle_B: 1.191 idt_B: 0.796 \n",
      "End of epoch 5 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 6 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 7 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 8 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 9 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 6, time: 0.252, data: 0.000) D_A: 0.699 G_A: 1.206 cycle_A: 0.939 idt_A: 0.403 D_B: 0.394 G_B: 0.695 cycle_B: 0.868 idt_B: 0.474 \n",
      "End of epoch 10 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 11 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 12 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 13 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 42, time: 0.267, data: 0.004) D_A: 0.220 G_A: 0.703 cycle_A: 1.262 idt_A: 0.532 D_B: 0.409 G_B: 0.929 cycle_B: 1.319 idt_B: 0.355 \n",
      "End of epoch 14 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 15 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 16 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 17 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 18 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 12, time: 0.364, data: 0.001) D_A: 0.105 G_A: 0.655 cycle_A: 0.861 idt_A: 0.431 D_B: 0.154 G_B: 0.521 cycle_B: 1.048 idt_B: 0.399 \n",
      "End of epoch 19 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 20 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 21 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 22 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 48, time: 0.267, data: 0.001) D_A: 0.164 G_A: 0.539 cycle_A: 1.035 idt_A: 0.470 D_B: 0.151 G_B: 0.418 cycle_B: 0.869 idt_B: 0.475 \n",
      "End of epoch 23 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 24 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 25 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 26 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 27 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 18, time: 0.267, data: 0.002) D_A: 0.261 G_A: 0.360 cycle_A: 0.792 idt_A: 0.408 D_B: 0.153 G_B: 0.454 cycle_B: 0.892 idt_B: 0.368 \n",
      "End of epoch 28 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 29 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 30 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 31 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 54, time: 0.267, data: 0.000) D_A: 0.211 G_A: 0.357 cycle_A: 0.718 idt_A: 0.320 D_B: 0.116 G_B: 0.477 cycle_B: 0.751 idt_B: 0.354 \n",
      "End of epoch 32 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 33 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 34 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 35 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 36 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 24, time: 0.389, data: 0.002) D_A: 0.151 G_A: 0.726 cycle_A: 0.888 idt_A: 0.352 D_B: 0.084 G_B: 0.716 cycle_B: 0.946 idt_B: 0.374 \n",
      "End of epoch 37 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 38 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 39 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 40, iters 2640\n",
      "End of epoch 40 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 60, time: 0.267, data: 0.006) D_A: 0.120 G_A: 0.609 cycle_A: 0.678 idt_A: 0.366 D_B: 0.071 G_B: 1.258 cycle_B: 0.817 idt_B: 0.313 \n",
      "End of epoch 41 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 42 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 43 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 44 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 45 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 30, time: 0.266, data: 0.002) D_A: 0.173 G_A: 0.307 cycle_A: 0.788 idt_A: 0.342 D_B: 0.120 G_B: 0.612 cycle_B: 0.722 idt_B: 0.349 \n",
      "End of epoch 46 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 47 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 48 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 49 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 66, time: 0.186, data: 0.001) D_A: 0.122 G_A: 0.538 cycle_A: 0.823 idt_A: 0.245 D_B: 0.102 G_B: 0.724 cycle_B: 0.565 idt_B: 0.377 \n",
      "End of epoch 50 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 51 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 52 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 53 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 54 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 36, time: 0.409, data: 0.568) D_A: 0.121 G_A: 0.566 cycle_A: 0.722 idt_A: 0.219 D_B: 0.105 G_B: 0.577 cycle_B: 0.549 idt_B: 0.319 \n",
      "End of epoch 55 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 56 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 57 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 58 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 59 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 6, time: 0.252, data: 0.000) D_A: 0.161 G_A: 0.775 cycle_A: 0.632 idt_A: 0.348 D_B: 0.054 G_B: 0.707 cycle_B: 0.712 idt_B: 0.272 \n",
      "End of epoch 60 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 61 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 62 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 63 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 42, time: 0.267, data: 0.001) D_A: 0.057 G_A: 1.091 cycle_A: 0.638 idt_A: 0.346 D_B: 0.092 G_B: 0.619 cycle_B: 0.683 idt_B: 0.265 \n",
      "End of epoch 64 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 65 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 66 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 67 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 68 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 12, time: 0.267, data: 0.001) D_A: 0.085 G_A: 0.835 cycle_A: 0.932 idt_A: 0.389 D_B: 0.131 G_B: 1.080 cycle_B: 0.812 idt_B: 0.375 \n",
      "End of epoch 69 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 70 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 71 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 72 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 48, time: 0.438, data: 0.004) D_A: 0.045 G_A: 0.783 cycle_A: 0.893 idt_A: 0.366 D_B: 0.090 G_B: 0.620 cycle_B: 0.841 idt_B: 0.391 \n",
      "End of epoch 73 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 74 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 75 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 76 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 77 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 18, time: 0.266, data: 0.003) D_A: 0.054 G_A: 0.608 cycle_A: 0.690 idt_A: 0.286 D_B: 0.109 G_B: 0.558 cycle_B: 0.554 idt_B: 0.300 \n",
      "End of epoch 78 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 79 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 80, iters 5280\n",
      "End of epoch 80 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 81 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 54, time: 0.267, data: 0.000) D_A: 0.272 G_A: 0.547 cycle_A: 1.058 idt_A: 0.337 D_B: 0.021 G_B: 0.689 cycle_B: 0.509 idt_B: 0.459 \n",
      "End of epoch 82 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 83 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 84 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 85 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 86 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 24, time: 0.267, data: 0.004) D_A: 0.037 G_A: 0.759 cycle_A: 0.902 idt_A: 0.321 D_B: 0.042 G_B: 0.646 cycle_B: 0.652 idt_B: 0.428 \n",
      "End of epoch 87 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 88 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 89 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 90 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 60, time: 0.468, data: 0.004) D_A: 0.058 G_A: 0.636 cycle_A: 0.728 idt_A: 0.320 D_B: 0.124 G_B: 0.308 cycle_B: 0.691 idt_B: 0.327 \n",
      "End of epoch 91 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 92 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 93 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 94 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 95 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 30, time: 0.267, data: 0.002) D_A: 0.078 G_A: 1.255 cycle_A: 1.044 idt_A: 0.371 D_B: 0.049 G_B: 0.747 cycle_B: 0.880 idt_B: 0.495 \n",
      "End of epoch 96 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 97 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 98 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 99 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 66, time: 0.186, data: 0.001) D_A: 0.038 G_A: 0.949 cycle_A: 0.713 idt_A: 0.315 D_B: 0.101 G_B: 1.446 cycle_B: 0.723 idt_B: 0.286 \n",
      "End of epoch 100 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 101 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 102 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 103 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 104 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 105, iters: 36, time: 0.267, data: 0.531) D_A: 0.111 G_A: 0.510 cycle_A: 0.748 idt_A: 0.289 D_B: 0.029 G_B: 0.616 cycle_B: 0.647 idt_B: 0.326 \n",
      "End of epoch 105 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 106 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 107 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 108 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 109 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 110, iters: 6, time: 0.471, data: 0.003) D_A: 0.062 G_A: 0.575 cycle_A: 0.630 idt_A: 0.281 D_B: 0.028 G_B: 0.837 cycle_B: 0.623 idt_B: 0.263 \n",
      "End of epoch 110 / 5100 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 111 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 112 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 113 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 114, iters: 42, time: 0.267, data: 0.001) D_A: 0.036 G_A: 0.985 cycle_A: 0.921 idt_A: 0.351 D_B: 0.018 G_B: 1.105 cycle_B: 0.719 idt_B: 0.381 \n",
      "End of epoch 114 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 115 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 116 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 117 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 118 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 119, iters: 12, time: 0.267, data: 0.000) D_A: 0.035 G_A: 1.056 cycle_A: 0.784 idt_A: 0.193 D_B: 0.055 G_B: 0.609 cycle_B: 0.477 idt_B: 0.352 \n",
      "End of epoch 119 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 120, iters 7920\n",
      "End of epoch 120 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 121 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 122 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 123, iters: 48, time: 0.267, data: 0.000) D_A: 0.080 G_A: 0.422 cycle_A: 0.963 idt_A: 0.240 D_B: 0.013 G_B: 0.974 cycle_B: 0.522 idt_B: 0.452 \n",
      "End of epoch 123 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 124 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 125 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 126 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 127 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 128, iters: 18, time: 0.501, data: 0.002) D_A: 0.242 G_A: 0.627 cycle_A: 0.789 idt_A: 0.174 D_B: 0.043 G_B: 0.904 cycle_B: 0.423 idt_B: 0.327 \n",
      "End of epoch 128 / 5100 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 129 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 130 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 131 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 132, iters: 54, time: 0.267, data: 0.001) D_A: 0.079 G_A: 0.642 cycle_A: 0.676 idt_A: 0.223 D_B: 0.022 G_B: 0.929 cycle_B: 0.494 idt_B: 0.290 \n",
      "End of epoch 132 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 133 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 134 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 135 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 136 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 137, iters: 24, time: 0.267, data: 0.003) D_A: 0.046 G_A: 0.708 cycle_A: 0.572 idt_A: 0.205 D_B: 0.014 G_B: 0.835 cycle_B: 0.484 idt_B: 0.230 \n",
      "End of epoch 137 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 138 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 139 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 140 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 141, iters: 60, time: 0.267, data: 0.002) D_A: 0.172 G_A: 0.674 cycle_A: 0.979 idt_A: 0.215 D_B: 0.257 G_B: 0.083 cycle_B: 0.557 idt_B: 0.418 \n",
      "End of epoch 141 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 142 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 143 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 144 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 145 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 146, iters: 30, time: 0.540, data: 0.002) D_A: 0.206 G_A: 0.855 cycle_A: 0.820 idt_A: 0.339 D_B: 0.101 G_B: 1.139 cycle_B: 0.733 idt_B: 0.354 \n",
      "End of epoch 146 / 5100 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 147 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 148 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 149 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 150, iters: 66, time: 0.186, data: 0.001) D_A: 0.056 G_A: 0.589 cycle_A: 0.950 idt_A: 0.237 D_B: 0.003 G_B: 0.989 cycle_B: 0.490 idt_B: 0.466 \n",
      "End of epoch 150 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 151 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 152 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 153 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 154 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 155, iters: 36, time: 0.267, data: 0.624) D_A: 0.057 G_A: 0.600 cycle_A: 0.667 idt_A: 0.269 D_B: 0.002 G_B: 0.979 cycle_B: 0.546 idt_B: 0.272 \n",
      "End of epoch 155 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 156 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 157 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 158 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 159 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 160, iters: 6, time: 0.252, data: 0.000) D_A: 0.120 G_A: 0.680 cycle_A: 0.820 idt_A: 0.288 D_B: 0.006 G_B: 1.004 cycle_B: 0.636 idt_B: 0.361 \n",
      "saving the model at the end of epoch 160, iters 10560\n",
      "End of epoch 160 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 161 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 162 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 163 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 164, iters: 42, time: 0.538, data: 0.001) D_A: 0.105 G_A: 0.767 cycle_A: 0.839 idt_A: 0.178 D_B: 0.002 G_B: 0.987 cycle_B: 0.391 idt_B: 0.392 \n",
      "End of epoch 164 / 5100 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 165 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 166 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 167 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 168 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 169, iters: 12, time: 0.267, data: 0.001) D_A: 0.090 G_A: 0.390 cycle_A: 0.606 idt_A: 0.390 D_B: 0.004 G_B: 0.914 cycle_B: 0.819 idt_B: 0.246 \n",
      "End of epoch 169 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 170 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 171 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 172 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 173, iters: 48, time: 0.267, data: 0.000) D_A: 0.063 G_A: 0.521 cycle_A: 0.803 idt_A: 0.225 D_B: 0.008 G_B: 0.905 cycle_B: 0.489 idt_B: 0.350 \n",
      "End of epoch 173 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 174 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 175 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 176 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 177 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 178, iters: 18, time: 0.267, data: 0.002) D_A: 0.122 G_A: 0.598 cycle_A: 0.961 idt_A: 0.243 D_B: 0.003 G_B: 0.994 cycle_B: 0.505 idt_B: 0.404 \n",
      "End of epoch 178 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 179 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 180 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 181 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 182, iters: 54, time: 0.572, data: 0.000) D_A: 0.048 G_A: 0.598 cycle_A: 0.715 idt_A: 0.324 D_B: 0.002 G_B: 0.998 cycle_B: 0.672 idt_B: 0.262 \n",
      "End of epoch 182 / 5100 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 183 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 184 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 185 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 186 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 187, iters: 24, time: 0.267, data: 0.002) D_A: 0.163 G_A: 0.364 cycle_A: 0.750 idt_A: 0.302 D_B: 0.003 G_B: 0.987 cycle_B: 0.664 idt_B: 0.326 \n",
      "End of epoch 187 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 188 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 189 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 190 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 191, iters: 60, time: 0.267, data: 0.003) D_A: 0.200 G_A: 0.275 cycle_A: 0.791 idt_A: 0.146 D_B: 0.001 G_B: 0.979 cycle_B: 0.308 idt_B: 0.362 \n",
      "End of epoch 191 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 192 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 193 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 194 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 195 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 196, iters: 30, time: 0.266, data: 0.003) D_A: 0.073 G_A: 0.618 cycle_A: 0.879 idt_A: 0.264 D_B: 0.002 G_B: 0.959 cycle_B: 0.551 idt_B: 0.401 \n",
      "End of epoch 196 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 197 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 198 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 199 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 200, iters: 66, time: 0.519, data: 0.000) D_A: 0.111 G_A: 0.516 cycle_A: 0.585 idt_A: 0.220 D_B: 0.003 G_B: 1.035 cycle_B: 0.464 idt_B: 0.209 \n",
      "saving the model at the end of epoch 200, iters 13200\n",
      "End of epoch 200 / 5100 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 201 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 202 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 203 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 204 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 205, iters: 36, time: 0.266, data: 0.570) D_A: 0.096 G_A: 0.500 cycle_A: 0.909 idt_A: 0.211 D_B: 0.004 G_B: 1.059 cycle_B: 0.464 idt_B: 0.425 \n",
      "End of epoch 205 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 206 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 207 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 208 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 209 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 210, iters: 6, time: 0.253, data: 0.000) D_A: 0.125 G_A: 0.413 cycle_A: 0.800 idt_A: 0.184 D_B: 0.003 G_B: 0.992 cycle_B: 0.405 idt_B: 0.363 \n",
      "End of epoch 210 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 211 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 212 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 213 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 214, iters: 42, time: 0.267, data: 0.003) D_A: 0.127 G_A: 0.645 cycle_A: 0.872 idt_A: 0.288 D_B: 0.003 G_B: 1.005 cycle_B: 0.619 idt_B: 0.376 \n",
      "End of epoch 214 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 215 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 216 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 217 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 218 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 219, iters: 12, time: 0.611, data: 0.001) D_A: 0.070 G_A: 0.395 cycle_A: 0.764 idt_A: 0.181 D_B: 0.296 G_B: 0.911 cycle_B: 0.415 idt_B: 0.321 \n",
      "End of epoch 219 / 5100 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 220 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 221 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 222 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 223, iters: 48, time: 0.267, data: 0.002) D_A: 0.262 G_A: 0.476 cycle_A: 0.759 idt_A: 0.367 D_B: 0.060 G_B: 0.360 cycle_B: 0.729 idt_B: 0.317 \n",
      "End of epoch 223 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 224 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 225 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 226 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 227 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 228, iters: 18, time: 0.267, data: 0.002) D_A: 0.075 G_A: 0.555 cycle_A: 0.784 idt_A: 0.329 D_B: 0.041 G_B: 0.626 cycle_B: 0.686 idt_B: 0.344 \n",
      "saving the latest model (epoch 228, total_iters 15000)\n",
      "End of epoch 228 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 229 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 230 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 231 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 232, iters: 54, time: 0.267, data: 0.001) D_A: 0.079 G_A: 0.423 cycle_A: 0.681 idt_A: 0.183 D_B: 0.071 G_B: 1.429 cycle_B: 0.428 idt_B: 0.280 \n",
      "End of epoch 232 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 233 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 234 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 235 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 236 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 237, iters: 24, time: 0.648, data: 0.002) D_A: 0.118 G_A: 0.517 cycle_A: 0.856 idt_A: 0.235 D_B: 0.132 G_B: 0.189 cycle_B: 0.541 idt_B: 0.375 \n",
      "End of epoch 237 / 5100 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 238 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 239 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 240, iters 15840\n",
      "End of epoch 240 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 241, iters: 60, time: 0.267, data: 0.002) D_A: 0.099 G_A: 0.603 cycle_A: 0.934 idt_A: 0.205 D_B: 0.020 G_B: 0.729 cycle_B: 0.479 idt_B: 0.380 \n",
      "End of epoch 241 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 242 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 243 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 244 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 245 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 246, iters: 30, time: 0.267, data: 0.002) D_A: 0.117 G_A: 0.615 cycle_A: 0.703 idt_A: 0.132 D_B: 0.005 G_B: 0.885 cycle_B: 0.307 idt_B: 0.284 \n",
      "End of epoch 246 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 247 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 248 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 249 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 250, iters: 66, time: 0.186, data: 0.002) D_A: 0.144 G_A: 0.426 cycle_A: 1.336 idt_A: 0.129 D_B: 0.003 G_B: 0.941 cycle_B: 0.302 idt_B: 0.641 \n",
      "End of epoch 250 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 251 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 252 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 253 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 254 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 255, iters: 36, time: 0.678, data: 0.542) D_A: 0.136 G_A: 0.396 cycle_A: 0.734 idt_A: 0.278 D_B: 0.013 G_B: 1.028 cycle_B: 0.564 idt_B: 0.317 \n",
      "End of epoch 255 / 5100 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 256 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 257 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 258 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 259 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 260, iters: 6, time: 0.253, data: 0.001) D_A: 0.228 G_A: 0.376 cycle_A: 0.843 idt_A: 0.255 D_B: 0.239 G_B: 0.673 cycle_B: 0.514 idt_B: 0.366 \n",
      "End of epoch 260 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 261 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 262 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 263 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 264, iters: 42, time: 0.267, data: 0.001) D_A: 0.148 G_A: 0.406 cycle_A: 0.733 idt_A: 0.237 D_B: 0.005 G_B: 1.011 cycle_B: 0.542 idt_B: 0.309 \n",
      "End of epoch 264 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 265 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 266 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 267 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 268 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 269, iters: 12, time: 0.267, data: 0.000) D_A: 0.103 G_A: 0.432 cycle_A: 0.576 idt_A: 0.244 D_B: 0.003 G_B: 1.005 cycle_B: 0.565 idt_B: 0.212 \n",
      "End of epoch 269 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 270 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 271 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 272 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 273, iters: 48, time: 0.687, data: 0.001) D_A: 0.118 G_A: 0.619 cycle_A: 0.793 idt_A: 0.245 D_B: 0.025 G_B: 1.268 cycle_B: 0.571 idt_B: 0.329 \n",
      "End of epoch 273 / 5100 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 274 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 275 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 276 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 277 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 278, iters: 18, time: 0.267, data: 0.002) D_A: 0.167 G_A: 0.655 cycle_A: 0.856 idt_A: 0.220 D_B: 0.028 G_B: 0.924 cycle_B: 0.491 idt_B: 0.382 \n",
      "End of epoch 278 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 279 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 280, iters 18480\n",
      "End of epoch 280 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 281 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 282, iters: 54, time: 0.267, data: 0.000) D_A: 0.141 G_A: 0.515 cycle_A: 0.586 idt_A: 0.206 D_B: 0.038 G_B: 0.989 cycle_B: 0.481 idt_B: 0.228 \n",
      "End of epoch 282 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 283 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 284 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 285 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 286 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 287, iters: 24, time: 0.267, data: 0.002) D_A: 0.127 G_A: 0.435 cycle_A: 0.705 idt_A: 0.282 D_B: 0.004 G_B: 0.966 cycle_B: 0.582 idt_B: 0.304 \n",
      "End of epoch 287 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 288 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 289 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 290 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 291, iters: 60, time: 0.716, data: 0.004) D_A: 0.266 G_A: 0.481 cycle_A: 0.675 idt_A: 0.165 D_B: 0.003 G_B: 0.996 cycle_B: 0.361 idt_B: 0.277 \n",
      "End of epoch 291 / 5100 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 292 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 293 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 294 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 295 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 296, iters: 30, time: 0.266, data: 0.003) D_A: 0.122 G_A: 0.632 cycle_A: 0.819 idt_A: 0.241 D_B: 0.116 G_B: 1.531 cycle_B: 0.514 idt_B: 0.333 \n",
      "End of epoch 296 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 297 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 298 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 299 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 300, iters: 66, time: 0.185, data: 0.000) D_A: 0.117 G_A: 0.413 cycle_A: 0.813 idt_A: 0.193 D_B: 0.037 G_B: 0.839 cycle_B: 0.509 idt_B: 0.346 \n",
      "End of epoch 300 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 301 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 302 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 303 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 304 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 305, iters: 36, time: 0.267, data: 0.511) D_A: 0.115 G_A: 0.385 cycle_A: 0.767 idt_A: 0.188 D_B: 0.033 G_B: 0.594 cycle_B: 0.459 idt_B: 0.317 \n",
      "End of epoch 305 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 306 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 307 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 308 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 309 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 310, iters: 6, time: 0.735, data: 0.001) D_A: 0.145 G_A: 0.566 cycle_A: 0.676 idt_A: 0.217 D_B: 0.057 G_B: 0.794 cycle_B: 0.496 idt_B: 0.281 \n",
      "End of epoch 310 / 5100 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 311 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 312 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 313 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 314, iters: 42, time: 0.267, data: 0.003) D_A: 0.085 G_A: 0.664 cycle_A: 0.727 idt_A: 0.215 D_B: 0.077 G_B: 1.039 cycle_B: 0.537 idt_B: 0.279 \n",
      "End of epoch 314 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 315 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 316 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 317 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 318 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 319, iters: 12, time: 0.267, data: 0.000) D_A: 0.139 G_A: 0.311 cycle_A: 0.828 idt_A: 0.236 D_B: 0.025 G_B: 0.906 cycle_B: 0.564 idt_B: 0.334 \n",
      "End of epoch 319 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 320, iters 21120\n",
      "End of epoch 320 / 5100 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 321 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 322 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 323, iters: 48, time: 0.266, data: 0.001) D_A: 0.105 G_A: 0.528 cycle_A: 1.015 idt_A: 0.154 D_B: 0.113 G_B: 1.245 cycle_B: 0.451 idt_B: 0.437 \n",
      "End of epoch 323 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 324 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 325 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 326 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 327 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 328, iters: 18, time: 0.769, data: 0.002) D_A: 0.145 G_A: 0.428 cycle_A: 0.757 idt_A: 0.294 D_B: 0.116 G_B: 0.355 cycle_B: 0.617 idt_B: 0.278 \n",
      "End of epoch 328 / 5100 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 329 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 330 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 331 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 332, iters: 54, time: 0.266, data: 0.001) D_A: 0.113 G_A: 0.531 cycle_A: 0.886 idt_A: 0.194 D_B: 0.130 G_B: 0.248 cycle_B: 0.520 idt_B: 0.397 \n",
      "End of epoch 332 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 333 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 334 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 335 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 336 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 337, iters: 24, time: 0.266, data: 0.002) D_A: 0.103 G_A: 0.548 cycle_A: 0.798 idt_A: 0.214 D_B: 0.141 G_B: 0.221 cycle_B: 0.543 idt_B: 0.340 \n",
      "End of epoch 337 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 338 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 339 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 340 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 341, iters: 60, time: 0.267, data: 0.003) D_A: 0.148 G_A: 0.456 cycle_A: 0.688 idt_A: 0.189 D_B: 0.114 G_B: 0.238 cycle_B: 0.556 idt_B: 0.270 \n",
      "End of epoch 341 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 342 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 343 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 344 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 345 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 346, iters: 30, time: 0.788, data: 0.002) D_A: 0.109 G_A: 0.433 cycle_A: 0.762 idt_A: 0.159 D_B: 0.146 G_B: 0.135 cycle_B: 0.400 idt_B: 0.323 \n",
      "End of epoch 346 / 5100 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 347 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 348 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 349 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 350, iters: 66, time: 0.186, data: 0.001) D_A: 0.103 G_A: 0.697 cycle_A: 0.716 idt_A: 0.204 D_B: 0.073 G_B: 0.296 cycle_B: 0.603 idt_B: 0.285 \n",
      "End of epoch 350 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 351 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 352 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 353 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 354 / 5100 \t Time Taken: 16 sec\n",
      "learning rate = 0.0002000\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kiYz08FbHwVC",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "071a7c73-5b3b-4370-fed3-2fea0330e536",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588348447539,
     "user_tz": -480,
     "elapsed": 3516,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    }
   },
   "source": [
    "!python train.py --dataroot ./datasets/4301 --name 4301_preprocess --model cycle_gan  --n_epochs 10000  --input_nc 1 --output_nc 1 --save_epoch_freq 40  --continue_train --epoch_count 5100"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "python3: can't open file 'train.py': [Errno 2] No such file or directory\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xA3iX520mq-h",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!python train.py --dataroot '/content/drive/My Drive/style_data' --name 4302_0 --model cycle_gan  --n_epochs 5000 --batch_size 6 --input_nc 1 --output_nc 1 --save_epoch_freq 40 "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8BIbEznUYtt",
    "colab_type": "text"
   },
   "source": [
    "Step2:use test to convert style A to style B return png file  get png path\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l_N9MbdsUKPD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!python  test.py   --dataroot '/content/drive/My Drive/style_data' --name 4302_0 --model cycle_gan   --input_nc 1 --output_nc 1 --preprocess none"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IrKEH-uQUXZ_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GITxMLoUTZU",
    "colab_type": "text"
   },
   "source": [
    "Step3.load png files and transfer them to npy file"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vj9tnV9LUL1v",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "import matplotlib;\n",
    "import numpy;\n",
    "from functions import *\n",
    "def visu123(save_path,\n",
    "            seismic_path,index=0,dimension=0):\n",
    "    transfer = np.zeros((350,500,1200))\n",
    "    print(transfer.shape)\n",
    "    load_path = '/content/drive/My Drive/cycle/pytorch-CycleGAN-and-pix2pix/results/4301_0/test_latest/images'\n",
    "    from PIL import Image\n",
    "    for index in range(222,271):\n",
    "        a = plt.imread('{}/{}_fake_B.png'.format(load_path, index))\n",
    "        print(a.shape)\n",
    "        picture = Image.open('{}/{}_fake_B.png'.format(load_path, index))\n",
    "        picture = picture.convert('L')\n",
    "        picture2 = np.asarray(picture)\n",
    "        print(picture2.shape)\n",
    "        transfer[index]=picture2\n",
    "    np.save('./transferData430',transfer)\n",
    "\n",
    "\n",
    "visu123(\"saved\",\"data/FYP_data/fault_sub_350IL_500t_1200XL.npy\",51,0)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXtc8REvlDwX",
    "colab_type": "text"
   },
   "source": [
    "step: 4.load npy file, training "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ifP0F97uvFg_",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "220cadc6-e171-4cfa-8e8b-5727952fb5ac",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588328194231,
     "user_tz": -480,
     "elapsed": 1364,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    }
   },
   "source": [
    "cd /content/drive/My Drive/Earthquake7"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Earthquake7\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c_9Q8-13Wcdt",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!python train.py --config config1.json --sp '/content/drive/My Drive/Earthquake7/transferData.npy'"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oenJVOvplJ-y",
    "colab_type": "text"
   },
   "source": [
    "step 5\n",
    "save_picture, examing the result "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y6t5X1U_qFh8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "outputId": "d7b17ce5-0130-4f93-f541-8b680a1686a8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588328200069,
     "user_tz": -480,
     "elapsed": 5074,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    }
   },
   "source": [
    "pip install cmapy"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmapy in /usr/local/lib/python3.6/dist-packages (0.6.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cmapy) (3.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cmapy) (1.18.3)\n",
      "Requirement already satisfied: opencv-python>=3.3 in /usr/local/lib/python3.6/dist-packages (from cmapy) (4.1.2.30)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->cmapy) (1.12.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uRitqJPhlJS-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!python save_predicted_picture.py --config config1.json --sp '/content/drive/My Drive/Earthquake7/transferData.npy' --resume 'saved/models/DeepLab/0430_104459/checkpoint-epoch5.pth'"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6qD8swOm_9H",
    "colab_type": "text"
   },
   "source": [
    "step 6\n",
    "\n",
    "apply the model in the dataset B, save_picture, get the result, compare.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KhzhIccPnGdW",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "684a1c19-e165-48ae-9720-2b75f99c09f1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588263656057,
     "user_tz": -480,
     "elapsed": 74237,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    }
   },
   "source": [
    "!python save_predicted_picture.py --config config1.json --sp '/content/drive/My Drive/datasets2/subGSBxl_t_il.npy' --resume 'saved/models/DeepLab/0430_104459/checkpoint-epoch5.pth'"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100\n",
      "483\n",
      "100% 37/37 [00:02<00:00, 13.00it/s]\n",
      "saved/picture/DeepLab/0430_161947/seismic_223.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_223.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_224.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_224.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_225.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_225.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_226.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_226.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_227.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_227.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_228.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_228.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_229.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_229.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_230.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_230.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_231.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_231.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_232.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_232.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_233.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_233.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_234.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_234.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_235.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_235.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_236.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_236.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_237.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_237.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_238.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_238.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_239.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_239.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_240.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_240.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_241.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_241.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_242.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_242.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_243.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_243.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_244.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_244.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_245.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_245.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_246.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_246.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_247.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_247.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_248.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_248.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_249.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_249.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_250.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_250.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_251.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_251.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_252.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_252.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_253.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_253.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_254.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_254.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_255.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_255.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_256.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_256.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_257.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_257.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_258.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_258.png\n",
      "saved/picture/DeepLab/0430_161947/seismic_259.png\n",
      "saved/picture/DeepLab/0430_161947/fusion_259.png\n",
      "Traceback (most recent call last):\n",
      "  File \"save_predicted_picture.py\", line 208, in <module>\n",
      "    main(config)\n",
      "  File \"save_predicted_picture.py\", line 147, in main\n",
      "    a = np.load(os.path.join(save_path, str(index) + '.npy'))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 428, in load\n",
      "    fid = open(os_fspath(file), \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'saved/picture/DeepLab/0430_161947/260.npy'\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pQyOI9RtyRaX",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "outputId": "2b972eee-4e3d-411f-fe20-b9161b610767",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588331353088,
     "user_tz": -480,
     "elapsed": 35986,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    }
   },
   "source": [
    "!python save_predicted_picture.py --config config0.json --sp '/content/drive/My Drive/datasets2/subGSBxl_t_il.npy' --resume  'saved/models/Unet/0501_094409/checkpoint-epoch9.pth'"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100\n",
      "483\n",
      "100% 15/15 [00:00<00:00, 16.43it/s]\n",
      "saved/picture/Unet/0501_110842/seismic_188.png\n",
      "saved/picture/Unet/0501_110842/fusion_188.png\n",
      "saved/picture/Unet/0501_110842/seismic_189.png\n",
      "saved/picture/Unet/0501_110842/fusion_189.png\n",
      "saved/picture/Unet/0501_110842/seismic_190.png\n",
      "saved/picture/Unet/0501_110842/fusion_190.png\n",
      "saved/picture/Unet/0501_110842/seismic_191.png\n",
      "saved/picture/Unet/0501_110842/fusion_191.png\n",
      "saved/picture/Unet/0501_110842/seismic_192.png\n",
      "saved/picture/Unet/0501_110842/fusion_192.png\n",
      "saved/picture/Unet/0501_110842/seismic_193.png\n",
      "saved/picture/Unet/0501_110842/fusion_193.png\n",
      "saved/picture/Unet/0501_110842/seismic_194.png\n",
      "saved/picture/Unet/0501_110842/fusion_194.png\n",
      "saved/picture/Unet/0501_110842/seismic_195.png\n",
      "saved/picture/Unet/0501_110842/fusion_195.png\n",
      "saved/picture/Unet/0501_110842/seismic_196.png\n",
      "saved/picture/Unet/0501_110842/fusion_196.png\n",
      "saved/picture/Unet/0501_110842/seismic_197.png\n",
      "saved/picture/Unet/0501_110842/fusion_197.png\n",
      "saved/picture/Unet/0501_110842/seismic_198.png\n",
      "saved/picture/Unet/0501_110842/fusion_198.png\n",
      "saved/picture/Unet/0501_110842/seismic_199.png\n",
      "saved/picture/Unet/0501_110842/fusion_199.png\n",
      "saved/picture/Unet/0501_110842/seismic_200.png\n",
      "saved/picture/Unet/0501_110842/fusion_200.png\n",
      "saved/picture/Unet/0501_110842/seismic_201.png\n",
      "saved/picture/Unet/0501_110842/fusion_201.png\n",
      "saved/picture/Unet/0501_110842/seismic_202.png\n",
      "saved/picture/Unet/0501_110842/fusion_202.png\n",
      "Traceback (most recent call last):\n",
      "  File \"save_predicted_picture.py\", line 208, in <module>\n",
      "    main(config)\n",
      "  File \"save_predicted_picture.py\", line 147, in main\n",
      "    a = np.load(os.path.join(save_path, str(index) + '.npy'))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 428, in load\n",
      "    fid = open(os_fspath(file), \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'saved/picture/Unet/0501_110842/203.npy'\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gc6JkMK9yRu_",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvTr7zNoyRzN",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8XFRP4OnY_j",
    "colab_type": "text"
   },
   "source": [
    "Step7_option: we could apply the original model to the datasetB and compare the result with that of the style-transfer model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KH1czeC-nvf2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!python save_predicted_picture.py --config config1.json --sp '/content/drive/My Drive/datasets2/subGSBxl_t_il.npy' --resume 'saved/models/DeepLab/0430_104459/checkpoint-epoch5.pth'"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tFzhgw5nY9g",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_08Rpqh2Z3Vc",
    "colab_type": "code",
    "outputId": "85a5a55a-611f-4a07-dc2d-458e1a8e9484",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1588240402236,
     "user_tz": -480,
     "elapsed": 7105,
     "user": {
      "displayName": "Yuan Wang",
      "photoUrl": "",
      "userId": "17198664945483720848"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    }
   },
   "source": [
    "pip install cmapy\n"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting cmapy\n",
      "  Downloading https://files.pythonhosted.org/packages/25/47/f1d2c686253bea1454cc7db687a09ae912fbe4648a86ef7fcd9765f7639f/cmapy-0.6.6.tar.gz\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cmapy) (3.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cmapy) (1.18.3)\n",
      "Requirement already satisfied: opencv-python>=3.3 in /usr/local/lib/python3.6/dist-packages (from cmapy) (4.1.2.30)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cmapy) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->cmapy) (1.12.0)\n",
      "Building wheels for collected packages: cmapy\n",
      "  Building wheel for cmapy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for cmapy: filename=cmapy-0.6.6-cp36-none-any.whl size=3959 sha256=1bebfeb353e7d58534a9412a42aea0e565791d4eb2e689cff02130e9ef630524\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/75/b1/b8645ff93df032bd16a383e7774e03d904476450d767fb1dcf\n",
      "Successfully built cmapy\n",
      "Installing collected packages: cmapy\n",
      "Successfully installed cmapy-0.6.6\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fsXnl4y7dTFh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "a=np.load('/content/drive/My Drive/Earthquake7/transferData.npy')\n",
    "print(a.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.imread(a[223])\n",
    "plt.imshow(a[223])\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx-y7bfciBU-",
    "colab_type": "text"
   },
   "source": [
    "出图检测\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YTXVrDTwf5lh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# !python save_predicted_picture.py --config config1.json --sp '/content/drive/My Drive/Earthquake7/transferData.npy'\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MzOPFqpkQ6M",
    "colab_type": "text"
   },
   "source": [
    "workflow:\n",
    "1.style transfer   style A to style B\n",
    "2.use test to convert style A to style B return png file \n",
    "3.load png files and transfer them to npy file\n",
    "4.load npy file, training \n",
    "5.save_picture, examing the result\n",
    "6.apply the model in the dataset B, save_picture, get the result, compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNhDpMnG4yLi",
    "colab_type": "text"
   },
   "source": [
    ""
   ]
  }
 ]
}